{"cells":[{"cell_type":"markdown","source":["References: https://www.tensorflow.org/recommenders/examples/basic_retrieval"],"metadata":{"id":"uV_yMabn4R0P"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgh7h9orWW8V","executionInfo":{"status":"ok","timestamp":1736183980560,"user_tz":-330,"elapsed":642,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# **RecSys Model 2: Retrieval**"],"metadata":{"id":"QQTUHJR8R2OO"}},{"cell_type":"markdown","source":["Real-world recommender systems are often composed of two stages:\n","\n","1.   **The retrieval stage** is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient.\n","\n","2.   **The ranking stage** takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.\n","\n","In this notebook, we're going to build the first stage, retrieval."],"metadata":{"id":"XH11XMmKQwfP"}},{"cell_type":"code","source":[],"metadata":{"id":"jhaSYLF8RViA","executionInfo":{"status":"ok","timestamp":1736183980895,"user_tz":-330,"elapsed":8,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Retrieval models are often composed of two sub-models:\n","\n","1.   **A query model** computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n","\n","2.   **A candidate model** computing the candidate representation (an equally-sized vector) using the candidate features\n","\n","The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query."],"metadata":{"id":"vJfei8CmRas-"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"UMQb_WniLfXU"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37462,"status":"ok","timestamp":1736184018350,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"RPz_0jFAJOYz","outputId":"af69da75-8e64-4c2a-dc3f-9c483301e9f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.17.1\n","Uninstalling tensorflow-2.17.1:\n","  Successfully uninstalled tensorflow-2.17.1\n","\u001b[33mWARNING: Skipping tensorflow-recommenders as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Temporary solution for a bug in the implementation of the tfrs.layers.factorized_top_k module.\n","# https://github.com/tensorflow/recommenders/issues/712#issuecomment-2041163592\n","\n","!pip uninstall tensorflow -y\n","!pip uninstall tensorflow-recommenders -y\n","#!pip uninstall tensorflow-datasets -y\n","\n","\n","import os\n","os.environ['TF_USE_LEGACY_KERAS'] = '1'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57002,"status":"ok","timestamp":1736184075347,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"8waSiZGeJXto","outputId":"3bb7aa99-d5cb-4965-c0cc-4c736ce38063"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q tensorflow==2.17\n","!pip install -q tensorflow-recommenders==0.7.3\n","\n","#!pip install -q --upgrade tensorflow-datasets\n","!pip install -q scann"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"dwHdgKCbJcGQ","executionInfo":{"status":"ok","timestamp":1736184084557,"user_tz":-330,"elapsed":9215,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["import pprint\n","import tempfile\n","\n","from typing import Dict, Text\n","\n","import numpy as np\n","import tensorflow as tf\n","#import tensorflow_datasets as tfds\n","\n","import json\n","import pandas as pd\n","from google.colab import drive"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"60EKmiAfJaGo","executionInfo":{"status":"ok","timestamp":1736184084891,"user_tz":-330,"elapsed":338,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["import tensorflow_recommenders as tfrs"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1736184084891,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"whJJiPhfJgYo","outputId":"aa9548b3-ad42-402e-f6bc-14f154858a4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.17.0\n"]}],"source":["print(tf.__version__)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1736184084891,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"8mu8sjB8Jh9w","outputId":"16e44e7e-49db-4353-b0e5-88cda41f2554"},"outputs":[{"output_type":"stream","name":"stdout","text":["v0.7.3\n"]}],"source":["print(tfrs.__version__)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Maq9iMa_NsZJ","executionInfo":{"status":"ok","timestamp":1736184084892,"user_tz":-330,"elapsed":6,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7bvRaxyBNt85"},"source":["# Importing and preprocessing the dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20628,"status":"ok","timestamp":1736184105514,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"-yDH0GPQNlix","outputId":"c598c305-7f14-42df-80c1-6116e82075aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"oGH_OmtFNpeC","executionInfo":{"status":"ok","timestamp":1736184105514,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["JSON_FILE = '/content/drive/My Drive/yelp_academic_dataset_review.json'"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1736184105514,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"lnJZM2LJJl3I"},"outputs":[],"source":["# Define the number of lines to read\n","#n_lines = 1000000\n","\n","# Read the specified number of lines into a list of dictionaries\n","#with open(JSON_FILE, \"r\") as file:\n","#    data = [json.loads(next(file)) for _ in range(n_lines)]\n","\n","# Convert the list of dictionaries into a DataFrame\n","#df = pd.DataFrame(data)"]},{"cell_type":"code","source":[],"metadata":{"id":"a67b7sDATlTu","executionInfo":{"status":"ok","timestamp":1736184105515,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Read the JSON lines file directly into a pandas DataFrame\n","#df = pd.read_json(JSON_FILE, lines=True)"],"metadata":{"id":"zReg_XM7TfZe","executionInfo":{"status":"ok","timestamp":1736184105515,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"V0ib6HZaTTC5","executionInfo":{"status":"ok","timestamp":1736184105515,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def get_data(filename):\n","  # Initialize an empty list to store selected attributes\n","  filtered_data = []\n","\n","  # Open and process JSON file line by line\n","  with open(filename, 'r') as file:\n","      for line in file:\n","          record = json.loads(line)\n","          # Extract only specific attributes\n","          filtered_data.append({'user_id': record['user_id'], 'business_id': record['business_id'], 'stars': record['stars']})\n","\n","  # Create a DataFrame\n","  return pd.DataFrame(filtered_data)"],"metadata":{"id":"EFKMZYfER-hc","executionInfo":{"status":"ok","timestamp":1736184105515,"user_tz":-330,"elapsed":8,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["df = get_data(JSON_FILE)"],"metadata":{"id":"17SdciVhcNxa","executionInfo":{"status":"ok","timestamp":1736184222667,"user_tz":-330,"elapsed":117160,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Display the first few rows\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CmJwlLPJTaJV","executionInfo":{"status":"ok","timestamp":1736184222667,"user_tz":-330,"elapsed":11,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"991478f3-3d24-4ace-bd68-91a0ed0a7e09"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["                  user_id             business_id  stars\n","0  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw    3.0\n","1  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ    5.0\n","2  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A    3.0\n","3  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA    5.0\n","4  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ    4.0\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1736184222667,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"Z8E-VAZ6TOLb","outputId":"dc0580ed-c0db-4b12-8bbb-9b74eac88e38"},"outputs":[{"output_type":"stream","name":"stdout","text":["6990280\n"]}],"source":["print(len(df)) # total number of entries"]},{"cell_type":"code","source":["def get_employee_ids_with_null_categories():\n","  JSON_FILE = '/content/drive/My Drive/yelp_academic_dataset_business.json'\n","\n","  df = pd.read_json(JSON_FILE, lines=True)\n","\n","  # Extract business_ids where categories is null (NaN)\n","  business_ids_with_null_categories = df.loc[df['categories'].isna(), 'business_id'].to_numpy()\n","\n","  return business_ids_with_null_categories"],"metadata":{"id":"mFkvxyllKA7t","executionInfo":{"status":"ok","timestamp":1736184222667,"user_tz":-330,"elapsed":8,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6953,"status":"ok","timestamp":1736184229612,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"hXrDfS0jOrAL"},"outputs":[],"source":["employee_ids_with_null_categories = get_employee_ids_with_null_categories()\n","\n","# Remove rows where business_id matches any value in employee_ids_with_null_categories\n","df = df[~df['business_id'].isin(employee_ids_with_null_categories)]"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1736184229615,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"bGwBVvFkPRCC","outputId":"52344055-111a-49d8-89e5-892dc8009962"},"outputs":[{"output_type":"stream","name":"stdout","text":["6989591\n"]}],"source":["print(len(df))  # number of entries after removing employees who have null 'categories'"]},{"cell_type":"code","source":[],"metadata":{"id":"S0yixd_9LN9V","executionInfo":{"status":"ok","timestamp":1736184229615,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1736184229931,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"d-46vcEnQ5a0","outputId":"b1621590-bf55-4df5-b169-f9d19aaf5cfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["              customer_id             employee_id  stars\n","0  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw    3.0\n","1  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ    5.0\n","2  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A    3.0\n","3  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA    5.0\n","4  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ    4.0\n"]}],"source":["# Rename columns\n","df = df.rename(columns={'user_id': 'customer_id', 'business_id': 'employee_id'})\n","\n","# Display the result\n","print(df.head())"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1736184229931,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"Wa3ikSkDhCkg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"g_oSCDw9ZRsn","executionInfo":{"status":"ok","timestamp":1736184232536,"user_tz":-330,"elapsed":2613,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["# Create TensorFlow Dataset using tf.data\n","tf_dataset = tf.data.Dataset.from_tensor_slices((\n","    {'customer_id': df['customer_id'].astype(str).values,      # Ensure conversion to strings\n","    'employee_id': df['employee_id'].astype(str).values,   # Ensure conversion to strings\n","    'stars': df['stars'].astype(float).values}  # Ensure conversion to floats\n","))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1736184232879,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"yrJnXLJ8ZvNO","outputId":"c281affd-9753-41db-a78b-dbb142fd373c"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'customer_id': b'mh_-eMZ6K5RLWhZyISBhwA',\n"," 'employee_id': b'XQfwVwDr-v0ZS3_CbbE5Xw',\n"," 'stars': 3.0}\n"]}],"source":["# Displaying a sample from the TensorFlow Dataset using pprint\n","for x in tf_dataset.take(1).as_numpy_iterator():\n","    pprint.pprint(x)"]},{"cell_type":"code","source":[],"metadata":{"id":"NKteMRn5TrM3","executionInfo":{"status":"ok","timestamp":1736184232879,"user_tz":-330,"elapsed":8,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["Let's figure out **unique employee ids** and **customer ids** present in the data.\n","\n","This is important because we **need to be able to map the raw values of our categorical features to embedding vectors** in our models. To do that, we **need a vocabulary that maps a raw feature value to an integer in a contiguous range**: *this allows us to look up the corresponding embeddings in our embedding tables*."],"metadata":{"id":"137IhtXeTV9e"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"csradRD3JK_R","executionInfo":{"status":"ok","timestamp":1736184559235,"user_tz":-330,"elapsed":326364,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["# Extracting & processing data to build vocabularies (for query and candidate towers)\n","\n","customers = tf_dataset.map(lambda x: x[\"customer_id\"])\n","employees = tf_dataset.map(lambda x: x[\"employee_id\"])\n","\n","customer_ids = customers.batch(1_000)\n","employee_ids = employees.batch(1_000)\n","\n","unique_customer_ids = np.unique(np.concatenate(list(customer_ids))) # vocabulary for the query tower\n","unique_employee_ids = np.unique(np.concatenate(list(employee_ids))) # vocabulary for the candidate tower"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1736184559237,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"tmOUySNPKVND","outputId":"06510c2a-a9a5-4123-a323-d3ec25d92414"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'---1lKK3aKOuomHnwAkAow', b'---2PmXbF47D870stH1jqA',\n","       b'---UgP94gokyCDuB5zUssA', b'---fa6ZK37T9NjkGKI4oSg',\n","       b'---r61b7EpVPkb4UVme5tA', b'---zemaUC8WeJeWKqS6p9Q',\n","       b'--034gGozmK4y5txuPsdAA', b'--0DrQkM0FT-yCQRWw82uQ',\n","       b'--0FNOzZkEQlz8WzS3WttQ', b'--0Jj_J_MmUJ51f1Y394Uw'], dtype=object)"]},"metadata":{},"execution_count":22}],"source":["unique_customer_ids[:10]"]},{"cell_type":"code","source":["print(len(unique_customer_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Deb8HV6aT9-P","executionInfo":{"status":"ok","timestamp":1736184559237,"user_tz":-330,"elapsed":15,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"3e895b9d-2dd8-4748-8548-a39d51a732a1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["1987685\n"]}]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1736184559237,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"nB_e4lGuKTZx","outputId":"3d4dd9dc-f156-47df-eecf-0690b15f97ce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'---kPU91CF4Lq2-WlRu9Lw', b'--0iUa4sNDFiZFrAdIWhZQ',\n","       b'--30_8IhuyMHbSOcNWd6DQ', b'--7PUidqRWpRSpXebiyxTg',\n","       b'--7jw19RH9JKXgFohspgQw', b'--8IbOsAAxjKRoYsBFL-PA',\n","       b'--9osgUCSDUWUkoTLdvYhQ', b'--ARBQr1WMsTWiwOKOj-FQ',\n","       b'--FWWsIwxRwuw9vIMImcQg', b'--FcbSxK1AoEtEAxOgBaCw'], dtype=object)"]},"metadata":{},"execution_count":24}],"source":["unique_employee_ids[:10]"]},{"cell_type":"code","source":["print(len(unique_employee_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGHNT7TVegd6","executionInfo":{"status":"ok","timestamp":1736184559237,"user_tz":-330,"elapsed":11,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"181fb11b-39f2-404f-e6df-7267a7ad97de"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["150243\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3_xKBYrKelj7","executionInfo":{"status":"ok","timestamp":1736184559237,"user_tz":-330,"elapsed":10,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"2nee8htWeq0Q","executionInfo":{"status":"ok","timestamp":1736184559237,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["# Data to train/test the model\n","tf_dataset = tf_dataset.map(lambda x: {\n","    \"customer_id\": x[\"customer_id\"],\n","    \"employee_id\": x[\"employee_id\"]\n","})"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"yaz3vE1AHTMY","executionInfo":{"status":"ok","timestamp":1736184559237,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["# Split data into a training and evaluation set\n","\n","tf.random.set_seed(42)\n","shuffled = tf_dataset.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n","\n","'''FOLLWING IS NOT APPLICABLE FOR THIS MODEL 2'''\n","# Since this model creates just a retrival index, it is suitable to use the test dataset also for training to index them as well.\n","# Because no unseen data/queries are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data.\n","# Therefore, following code snippets to create train and test splits are ommitted during execution.\n","\n","trainset_size = round(len(shuffled) * 0.8)\n","testset_size = round(len(shuffled) * 0.2)\n","\n","train = shuffled.take(trainset_size)\n","test = shuffled.skip(trainset_size).take(testset_size)"]},{"cell_type":"markdown","metadata":{"id":"oHeilbgtMHLq"},"source":["# Implementing a model\n"," A two-tower retrieval model, we can build each tower separately and then combine them in the final model."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"5IcQlJZGMNox","executionInfo":{"status":"ok","timestamp":1736184559238,"user_tz":-330,"elapsed":10,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["# The dimensionality of the query and candidate representations\n","embedding_dimension = 32"]},{"cell_type":"markdown","metadata":{"id":"IqpvJNbKMOzB"},"source":["## The query tower\n","A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n","\n","\n"," Use Keras preprocessing layers to first convert customer ids to integers, and then convert those to customer id embeddings via an `Embedding` layer. Note that we use the list of unique customer id we computed earlier as a vocabulary"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"W1zdEThnMVmL","executionInfo":{"status":"ok","timestamp":1736184563409,"user_tz":-330,"elapsed":4181,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["customer_model = tf.keras.Sequential([\n","  tf.keras.layers.StringLookup(\n","      vocabulary=unique_customer_ids, mask_token=None),\n","  # We add an additional embedding to account for unknown tokens (to handle unseen or out-of-vocabulary (OOV) data.)\n","  tf.keras.layers.Embedding(len(unique_customer_ids) + 1, embedding_dimension)\n","])"]},{"cell_type":"markdown","metadata":{"id":"rWfrCS2QM3-6"},"source":["## The candidate tower\n","A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n","\n"," Use Keras preprocessing layers to first convert employee ids to integers, and then convert those to employee id embeddings via an `Embedding` layer. Note that we use the list of unique employee ids we computed earlier as a vocabulary"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"mKJyyy-MM5F7","executionInfo":{"status":"ok","timestamp":1736184563409,"user_tz":-330,"elapsed":5,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["employee_model = tf.keras.Sequential([\n","  tf.keras.layers.StringLookup(\n","      vocabulary=unique_employee_ids, mask_token=None),\n","  # We add an additional embedding to account for unknown tokens (to handle unseen or out-of-vocabulary (OOV) data.)\n","  tf.keras.layers.Embedding(len(unique_employee_ids) + 1, embedding_dimension)\n","])"]},{"cell_type":"markdown","metadata":{"id":"QVkZmj_bNZQq"},"source":["## Metrics\n","\n","In our training data we have positive (customer, employee) pairs. To figure out how good our model is, we need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates: if the score for the positive pair is higher than for all other candidates, our model is highly accurate.\n","\n","To do this, we can use the `tfrs.metrics.FactorizedTopK metric`. The metric has one required argument: the dataset of candidates that are used as implicit negatives for evaluation.\n","\n","In our case, that's the employee ids dataset, converted into embeddings via our employee model:"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"idG8KHIZNaCj","executionInfo":{"status":"ok","timestamp":1736184563750,"user_tz":-330,"elapsed":346,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["metrics = tfrs.metrics.FactorizedTopK(\n","  candidates=employees.batch(128).map(employee_model)\n",")"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"xkTU6h6rOIfC","executionInfo":{"status":"ok","timestamp":1736184563750,"user_tz":-330,"elapsed":13,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ffmj0RoxOIu7"},"source":["## Loss\n","\n","The next component is the loss used to train our model. TFRS has several loss layers and tasks to make this easy.\n","\n","In this instance, we'll make use of the Retrieval task object: a convenience wrapper that bundles together the loss function and metric computation:"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"1I8uU7haOJkb","executionInfo":{"status":"ok","timestamp":1736184563750,"user_tz":-330,"elapsed":13,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["task = tfrs.tasks.Retrieval(\n","  metrics=metrics\n",")"]},{"cell_type":"markdown","source":["The task itself is a Keras layer that takes the query and candidate embeddings as arguments, and returns the computed loss: we'll use that to implement the model's training loop."],"metadata":{"id":"_gbt8BgNYP6B"}},{"cell_type":"code","execution_count":32,"metadata":{"id":"Jt7DKFnxOmSH","executionInfo":{"status":"ok","timestamp":1736184563750,"user_tz":-330,"elapsed":12,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yjV3Z9WuOmbW"},"source":["## The full model\n","\n","We can now put it all together into a model. TFRS exposes a base model class (`tfrs.models.Model`) which streamlines building models: all we need to do is to set up the components in the` __init__` method, and implement the compute_loss method, taking in the raw features and returning a loss value.\n","\n","The base model will then take care of creating the appropriate training loop to fit our model."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"_I1SyMenOnd6","executionInfo":{"status":"ok","timestamp":1736184878884,"user_tz":-330,"elapsed":309,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["class YelpModel(tfrs.Model):\n","\n","  def __init__(self, category_model, employee_model):\n","    super().__init__()\n","    self.customer_model: tf.keras.Model = customer_model\n","    self.employee_model: tf.keras.Model = employee_model\n","    self.task: tf.keras.layers.Layer = task\n","\n","  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n","    # We pick out the customer features and pass them into the customer model.\n","    customer_embeddings = self.customer_model(features[\"customer_id\"])\n","    # And pick out the employee features and pass them into the employee model,\n","    # getting embeddings back.\n","    positive_employee_embeddings = self.employee_model(features[\"employee_id\"])\n","\n","    #if training:\n","      # The task computes the loss and not the metrics during training to speed up the process.\n","    #  return self.task(customer_embeddings, positive_employee_embeddings, compute_metrics=False)\n","\n","\n","    # The task computes the loss and the metrics.\n","    return self.task(customer_embeddings, positive_employee_embeddings, compute_metrics=False)"]},{"cell_type":"markdown","source":["The `tfrs.Model` base class is a simply convenience class: it allows us to compute both training and test losses using the same method."],"metadata":{"id":"ibYeksErYpPR"}},{"cell_type":"code","execution_count":33,"metadata":{"id":"FjKSbhEjP6RD","executionInfo":{"status":"ok","timestamp":1736184563750,"user_tz":-330,"elapsed":12,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5oaknpX7P6aD"},"source":["# Fitting and evaluating\n","\n","After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model.\n","\n","Let's first instantiate the model."]},{"cell_type":"code","execution_count":46,"metadata":{"id":"o6zWRWDSP7LT","executionInfo":{"status":"ok","timestamp":1736184881957,"user_tz":-330,"elapsed":514,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["model = YelpModel(customer_model, employee_model)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"]},{"cell_type":"markdown","source":["Then shuffle, batch, and cache the training and evaluation data"],"metadata":{"id":"iW83Dg9ZZkzc"}},{"cell_type":"code","execution_count":47,"metadata":{"id":"hMFzJ_vKQF37","executionInfo":{"status":"ok","timestamp":1736184883337,"user_tz":-330,"elapsed":3,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"outputs":[],"source":["'''FOLLWING IS NOT APPLICABLE FOR THIS MODEL 2'''\n","# Since this model creates just a retrival index, it is suitable to use the test dataset also for training to index them as well.\n","# Because no unseen data/queries are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data.\n","# Therefore, following code snippets to create train and test splits are ommitted during execution.\n","\n","cached_train = train.shuffle(100_000).batch(8192).cache()\n","cached_test = test.batch(4096).cache()\n","\n","#cached_train = shuffled.shuffle(100_000).batch(8192).cache()"]},{"cell_type":"markdown","source":["Then train the model:"],"metadata":{"id":"yBfIajDvZn2y"}},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3035989,"status":"ok","timestamp":1736187921505,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"SQLHmWpfQG0D","outputId":"c126c156-d648-4561-f49b-f5edee163eb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","683/683 [==============================] - 1124s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 65847.4759 - regularization_loss: 0.0000e+00 - total_loss: 65847.4759\n","Epoch 2/3\n","683/683 [==============================] - 935s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 56073.2476 - regularization_loss: 0.0000e+00 - total_loss: 56073.2476\n","Epoch 3/3\n","683/683 [==============================] - 939s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49847.0881 - regularization_loss: 0.0000e+00 - total_loss: 49847.0881\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf_keras.src.callbacks.History at 0x7df3137f3370>"]},"metadata":{},"execution_count":48}],"source":["model.fit(cached_train, epochs=3)"]},{"cell_type":"markdown","source":["As the model trains, the loss is falling and a set of top-k retrieval metrics is updated. These tell us whether the true positive is in the top-k retrieved items from the entire candidate set. For example, a top-5 categorical accuracy metric of 0.2 would tell us that, on average, the true positive is in the top 5 retrieved items 20% of the time.\n","\n","Note that, in this example, we evaluate the metrics during training as well as evaluation. Because this can be quite slow with large candidate sets, it may be prudent to turn metric calculation off in training, and only run it in evaluation.\n","\n","Finally, we can evaluate our model on the test set:"],"metadata":{"id":"bFuNY5UOZzdp"}},{"cell_type":"code","execution_count":49,"metadata":{"id":"sIpdODPzQI-q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736188178645,"user_tz":-330,"elapsed":245135,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"940cc960-9cf8-4074-cf02-21d42a01c346"},"outputs":[{"output_type":"stream","name":"stdout","text":["342/342 [==============================] - 245s 347ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32130.2739 - regularization_loss: 0.0000e+00 - total_loss: 32130.2739\n"]},{"output_type":"execute_result","data":{"text/plain":["{'factorized_top_k/top_1_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_5_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_50_categorical_accuracy': 0.0,\n"," 'factorized_top_k/top_100_categorical_accuracy': 0.0,\n"," 'loss': 8363.802734375,\n"," 'regularization_loss': 0,\n"," 'total_loss': 8363.802734375}"]},"metadata":{},"execution_count":49}],"source":["'''FOLLWING IS NOT APPLICABLE FOR THIS MODEL 2'''\n","# Since this model creates just a retrival index, it is suitable to use the test dataset also for training to index them as well.\n","# Because no unseen data/queries are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data.\n","# Therefore, following code snippet to test the model is ommitted during execution.\n","\n","\n","model.evaluate(cached_test, return_dict=True)"]},{"cell_type":"markdown","source":["## Making predictions\n","\n","Now that we have a model, we would like to be able to make predictions. We can use the `tfrs.layers.factorized_top_k.BruteForc`e layer to do this."],"metadata":{"id":"j2pQo_REcgxK"}},{"cell_type":"code","source":["unique_employee_ids = tf.constant(unique_employee_ids)  # Convert to Tensor to make the data (numpy array) ready for subsequent TensorFlow operations\n","unique_employee_ids = tf.data.Dataset.from_tensor_slices(unique_employee_ids)  # Convert the tensor into a Dataset"],"metadata":{"id":"_eTWxZ89kU1t","executionInfo":{"status":"ok","timestamp":1736188294510,"user_tz":-330,"elapsed":453,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Create a model that takes in raw query features, and\n","index = tfrs.layers.factorized_top_k.BruteForce(model.customer_model, k=1000)\n","# recommends employees out of the entire unique employee dataset.\n","index.index_from_dataset(\n","  tf.data.Dataset.zip((unique_employee_ids.batch(1000), unique_employee_ids.batch(1000).map(model.employee_model)))\n",")\n","\n","# Get recommendations.\n","_, employee_ids = index(tf.constant([\"Ha3iJu77CxlrFm-vQRs_8g\"]), k=20)\n","print(f\"Recommendations for customer 'Ha3iJu77CxlrFm-vQRs_8g': {employee_ids[0, :5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyuWYIy5c9uc","executionInfo":{"status":"ok","timestamp":1736188298252,"user_tz":-330,"elapsed":894,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"48901fbd-b3d0-475a-e6c3-58f1ff19f36b"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Recommendations for customer 'Ha3iJu77CxlrFm-vQRs_8g': [b'YbnJYHNp_fHbI-hcFg48vQ' b'DD3TxygdxBxKh9gbjCuLDA'\n"," b'1bJxvwuMTyXmQGu90WLPhA' b'W0vdz23JQtVQX5vJkiCj3g'\n"," b'lTCoYu00AUV0SHxOa-XXBw']\n"]}]},{"cell_type":"code","source":["print(len(employee_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihC9iajulcLF","executionInfo":{"status":"ok","timestamp":1736188305905,"user_tz":-330,"elapsed":462,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"27b1727e-73c9-47cb-9518-432da088bdd2"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["20\n"]}]},{"cell_type":"markdown","source":["Of course, the BruteForce layer is going to be too slow to serve a model with many possible candidates. The following sections shows how to speed this up by using an approximate retrieval index."],"metadata":{"id":"fcwpvTWTj079"}},{"cell_type":"code","source":[],"metadata":{"id":"V7RBsTunj140"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["An approximate retrieval index to speed up predictions. This will make it possible to efficiently surface recommendations from sets of tens of millions of candidates.\n","\n","To do so, we can use the `scann` package. This is an optional dependency of TFRS, and we installed it separately at the beginning of this notebook by calling `!pip install -q scann`.\n","\n","Once installed we can use the TFRS `ScaNN` layer:"],"metadata":{"id":"v6LiHiP5j8h9"}},{"cell_type":"code","source":["# Create a model that takes in raw query features, and\n","scann_index = tfrs.layers.factorized_top_k.ScaNN(model.customer_model, k=1000)\n","# recommends employees out of the entire unique employee dataset.\n","scann_index.index_from_dataset(\n","  tf.data.Dataset.zip((unique_employee_ids.batch(1000), unique_employee_ids.batch(1000).map(model.employee_model)))\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rhJe2YzBkMiN","executionInfo":{"status":"ok","timestamp":1736188317377,"user_tz":-330,"elapsed":4227,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"f9dee875-8534-45bb-b687-9eff0bb53c5c"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7df31381ad10>"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["This layer will perform approximate lookups: this makes retrieval slightly less accurate, but orders of magnitude faster on large candidate sets."],"metadata":{"id":"MWAGxbrnkOwj"}},{"cell_type":"code","source":["# Get recommendations.\n","_, employee_ids = scann_index(tf.constant([\"Ha3iJu77CxlrFm-vQRs_8g\"]), k=20)\n","print(f\"Recommendations for customer 'Ha3iJu77CxlrFm-vQRs_8g': {employee_ids[0, :5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FhU1h6pdkPM5","executionInfo":{"status":"ok","timestamp":1736188319816,"user_tz":-330,"elapsed":476,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"8de21336-43f8-4ec1-a666-495994497696"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Recommendations for customer 'Ha3iJu77CxlrFm-vQRs_8g': [b'W0vdz23JQtVQX5vJkiCj3g' b'SbdL-8NSmTWgSwdGZBa7WQ'\n"," b'lTCoYu00AUV0SHxOa-XXBw' b'H-1qpp_77KggOAr9htUrEw'\n"," b'lS1dmSXpAtQqT04eRm9kiA']\n"]}]},{"cell_type":"code","source":["print(len(employee_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqHAFlYelgfN","executionInfo":{"status":"ok","timestamp":1736190419259,"user_tz":-330,"elapsed":993,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"2df6f55b-8121-4158-8b15-9005c01348d0"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["20\n"]}]},{"cell_type":"markdown","source":["# Model serving\n","\n","After the model is trained, we need a way to deploy it.\n","\n","In a two-tower retrieval model, serving has two components:\n","\n","\n","*   **a serving query model**, taking in features of the query and transforming them into a query embedding, and\n","*   **a serving candidate model**. This most often takes the form of an approximate nearest neighbours (ANN) index which allows fast approximate lookup of candidates in response to a query produced by the query model.\n","\n","\n","In TFRS, both components can be packaged into a single exportable model, giving us a model that takes the raw category names and returns the ids of top/most similar employees for that category. This is done via exporting the model to a `SavedModel` format, which makes it possible to serve using TensorFlow Serving.\n","\n","To deploy a model like this, we simply export the `BruteForce` layer and/or `ScaNN` layer we created above:"],"metadata":{"id":"4yBsym4DrXIA"}},{"cell_type":"code","source":["# Export the query model.\n","with tempfile.TemporaryDirectory() as tmp:\n","  path = os.path.join(tmp, \"model\")\n","\n","  # Save the index.\n","  tf.saved_model.save(\n","      scann_index,\n","      path,\n","      options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n","  )\n","\n","  # Load it back; can also be done in TensorFlow Serving.\n","  loaded = tf.saved_model.load(path)\n","\n","  # Pass a customer id in, get top predicted employee ids back.\n","  scores, employee_ids = loaded(tf.constant([\"Ha3iJu77CxlrFm-vQRs_8g\"]))\n","\n","  print(f\"Recommendations for customer 'Ha3iJu77CxlrFm-vQRs_8g': {employee_ids[0][:5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OaqDWO9sXsX","executionInfo":{"status":"ok","timestamp":1736190630788,"user_tz":-330,"elapsed":208554,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"bbb73894-2584-4907-c24c-5f7a0a128156"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"]},{"output_type":"stream","name":"stdout","text":["Recommendations for customer 'Ha3iJu77CxlrFm-vQRs_8g': [b'W0vdz23JQtVQX5vJkiCj3g' b'SbdL-8NSmTWgSwdGZBa7WQ'\n"," b'lTCoYu00AUV0SHxOa-XXBw' b'H-1qpp_77KggOAr9htUrEw'\n"," b'lS1dmSXpAtQqT04eRm9kiA']\n"]}]},{"cell_type":"code","source":["print(len(employee_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3rI2kmutf9Q","executionInfo":{"status":"ok","timestamp":1736190637403,"user_tz":-330,"elapsed":1028,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"3eb707a4-6d41-46ad-8a75-47ebfe7456c4"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n"]}]},{"cell_type":"code","source":["# Define the folder path for saving the model\n","save_dir = '/content/drive/My Drive/Colab Notebooks/Saved Models'\n","#save_dir = '/content/Saved Model'\n","\n","# Ensure the folder exists\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# Path to save the model\n","model_path = os.path.join(save_dir, \"recsys_model_two_retrieval\")\n","\n","# Save the ScaNN index\n","tf.saved_model.save(\n","    scann_index,\n","    model_path,\n","    options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",")\n","\n","# Load the model back\n","loaded = tf.saved_model.load(model_path)\n","\n","# Pass a category name and get top recommendations\n","scores, employee_ids = loaded(tf.constant([\"Ha3iJu77CxlrFm-vQRs_8g\"]))\n","\n","print(f\"Recommendations for customer 'Ha3iJu77CxlrFm-vQRs_8g': {employee_ids[0][:5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kf93X5vJyT3I","executionInfo":{"status":"ok","timestamp":1736190733879,"user_tz":-330,"elapsed":93391,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"73be7a06-46e9-4fc2-91f1-1239567b02c2"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"]},{"output_type":"stream","name":"stdout","text":["Recommendations for customer 'Ha3iJu77CxlrFm-vQRs_8g': [b'W0vdz23JQtVQX5vJkiCj3g' b'SbdL-8NSmTWgSwdGZBa7WQ'\n"," b'lTCoYu00AUV0SHxOa-XXBw' b'H-1qpp_77KggOAr9htUrEw'\n"," b'lS1dmSXpAtQqT04eRm9kiA']\n"]}]},{"cell_type":"code","source":["print(len(employee_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vb9HpNLX0Fqy","executionInfo":{"status":"ok","timestamp":1736190733879,"user_tz":-330,"elapsed":3,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"c5331367-6ba3-4c09-efba-37e9f7fecc60"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n"]}]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMbIhYm3Q5QK9p/zYIt8Lom"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}