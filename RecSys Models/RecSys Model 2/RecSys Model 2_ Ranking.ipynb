{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNron3IeXJJ/+SQOiLDz+3/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["References: https://www.tensorflow.org/recommenders/examples/basic_ranking"],"metadata":{"id":"Rv9kYIf7WZ7T"}},{"cell_type":"code","source":[],"metadata":{"id":"geYC-_GuWmB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **RecSys Model 2: Ranking**"],"metadata":{"id":"UlRijpSiWmK7"}},{"cell_type":"markdown","source":["Real-world recommender systems are often composed of two stages:\n","\n","1. **The retrieval stage** is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient.\n","2. **The ranking stage** takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.\n","\n","We're going to focus on the second stage, ranking."],"metadata":{"id":"oRIA4JThWvO7"}},{"cell_type":"code","source":[],"metadata":{"id":"1VWLxaJGXNF-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"5R_c35JNXOeT"}},{"cell_type":"code","source":["# Temporary solution for a bug in the implementation of the tfrs.layers.factorized_top_k module.\n","# https://github.com/tensorflow/recommenders/issues/712#issuecomment-2041163592\n","\n","!pip uninstall tensorflow -y\n","!pip uninstall tensorflow-recommenders -y\n","#!pip uninstall tensorflow-datasets -y\n","\n","\n","import os\n","os.environ['TF_USE_LEGACY_KERAS'] = '1'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMbzBVRtXQDb","executionInfo":{"status":"ok","timestamp":1736199824926,"user_tz":-330,"elapsed":46918,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"ee84b8bc-3708-4e2d-9c78-1cc1803e239a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.17.1\n","Uninstalling tensorflow-2.17.1:\n","  Successfully uninstalled tensorflow-2.17.1\n","\u001b[33mWARNING: Skipping tensorflow-recommenders as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install -q tensorflow==2.17\n","!pip install -q tensorflow-recommenders==0.7.3\n","\n","#!pip install -q --upgrade tensorflow-datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"asLLbY7vX2Gc","executionInfo":{"status":"ok","timestamp":1736199880550,"user_tz":-330,"elapsed":55632,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"90354921-4e06-456f-a5c0-5452d733705d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import pprint\n","import tempfile\n","\n","from typing import Dict, Text\n","\n","import numpy as np\n","import tensorflow as tf\n","#import tensorflow_datasets as tfds\n","\n","import json\n","import pandas as pd\n","from google.colab import drive"],"metadata":{"id":"tpMgXLYbX2oc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow_recommenders as tfrs"],"metadata":{"id":"hJDA1Lz5X5Yb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B4JplLspX9Bz","executionInfo":{"status":"ok","timestamp":1736199891087,"user_tz":-330,"elapsed":7,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"6175a449-52f1-4802-c726-a6679b61042b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.17.0\n"]}]},{"cell_type":"code","source":["print(tfrs.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vl6_nMr0X-bU","executionInfo":{"status":"ok","timestamp":1736199891087,"user_tz":-330,"elapsed":6,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"91fd95fc-6b8f-4c9f-f36a-674d7c7bd020"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["v0.7.3\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JS2CLJWOYSOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Importing and preprocessing the dataset"],"metadata":{"id":"TupPSN71YSUr"}},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTKNIPoMYW5L","executionInfo":{"status":"ok","timestamp":1736199912164,"user_tz":-330,"elapsed":21081,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"fdd2c5e6-74f6-4394-d375-d475b08d7e11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["JSON_FILE = '/content/drive/My Drive/yelp_academic_dataset_review.json'"],"metadata":{"id":"McA1o05sYYx0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the number of lines to read\n","#n_lines = 25000\n","\n","# Read the specified number of lines into a list of dictionaries\n","#with open(JSON_FILE, \"r\") as file:\n","#    data = [json.loads(next(file)) for _ in range(n_lines)]\n","\n","# Convert the list of dictionaries into a DataFrame\n","#df = pd.DataFrame(data)"],"metadata":{"id":"hAjLrrXyYbKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LXm0bXjyeSAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read the JSON lines file directly into a pandas DataFrame\n","#df = pd.read_json(JSON_FILE, lines=True)"],"metadata":{"id":"IPBIj9oweIp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0_VuIM-geXKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_data(filename):\n","  # Initialize an empty list to store selected attributes\n","  filtered_data = []\n","\n","  # Open and process JSON file line by line\n","  with open(filename, 'r') as file:\n","      for line in file:\n","          record = json.loads(line)\n","          # Extract only specific attributes\n","          filtered_data.append({'user_id': record['user_id'], 'business_id': record['business_id'], 'stars': record['stars']})\n","\n","  # Create a DataFrame\n","  return pd.DataFrame(filtered_data)"],"metadata":{"id":"PIQS5YMmeXSK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = get_data(JSON_FILE)"],"metadata":{"id":"AJ04B5bVeaGh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the first few rows\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kFsNxDkeMOD","executionInfo":{"status":"ok","timestamp":1736200024081,"user_tz":-330,"elapsed":11,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"d7b083ca-aad4-4024-8231-64ea0ef0b640"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                  user_id             business_id  stars\n","0  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw    3.0\n","1  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ    5.0\n","2  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A    3.0\n","3  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA    5.0\n","4  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ    4.0\n"]}]},{"cell_type":"code","source":["print(len(df)) # total number of entries"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWpfi1gFYdQl","executionInfo":{"status":"ok","timestamp":1736200024082,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"dd75edf1-3dae-4d02-e09d-7ddc29ad596a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6990280\n"]}]},{"cell_type":"code","source":["def get_employee_ids_with_null_categories():\n","  JSON_FILE = '/content/drive/My Drive/yelp_academic_dataset_business.json'\n","\n","  df = pd.read_json(JSON_FILE, lines=True)\n","\n","  # Extract business_ids where categories is null (NaN)\n","  business_ids_with_null_categories = df.loc[df['categories'].isna(), 'business_id'].to_numpy()\n","\n","  return business_ids_with_null_categories"],"metadata":{"id":"uaIhL75becyK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["employee_ids_with_null_categories = get_employee_ids_with_null_categories()\n","\n","# Remove rows where business_id matches any value in employee_ids_with_null_categories\n","df = df[~df['business_id'].isin(employee_ids_with_null_categories)]"],"metadata":{"id":"IvZbi2J3efZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(df))  # number of entries after removing employees who have null 'categories'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYc3GrBTejEB","executionInfo":{"status":"ok","timestamp":1736200032422,"user_tz":-330,"elapsed":5,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"ac3436c3-cd7c-46b6-ccd5-bacc18cee20a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6989591\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1U0mJ86-e5qi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Rename columns\n","df = df.rename(columns={'user_id': 'customer_id', 'business_id': 'employee_id'})\n","\n","# Display the result\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqSH2gdNe5v5","executionInfo":{"status":"ok","timestamp":1736200032724,"user_tz":-330,"elapsed":5,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"8a74985a-fc03-4e26-e703-2e66e0f28b93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              customer_id             employee_id  stars\n","0  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw    3.0\n","1  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ    5.0\n","2  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A    3.0\n","3  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA    5.0\n","4  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ    4.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"p19_rL6Be-NR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create TensorFlow Dataset using tf.data\n","tf_dataset = tf.data.Dataset.from_tensor_slices((\n","    {'customer_id': df['customer_id'].astype(str).values,      # Ensure conversion to strings\n","    'employee_id': df['employee_id'].astype(str).values,   # Ensure conversion to strings\n","    'stars': df['stars'].astype(float).values}  # Ensure conversion to floats\n","))"],"metadata":{"id":"YkehlSJae-R5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Displaying a sample from the TensorFlow Dataset using pprint\n","for x in tf_dataset.take(1).as_numpy_iterator():\n","    pprint.pprint(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Dyv0pA7Y77s","executionInfo":{"status":"ok","timestamp":1736200036472,"user_tz":-330,"elapsed":571,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"8ae6fa48-7462-4913-f91f-ae0be43e454c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'customer_id': b'mh_-eMZ6K5RLWhZyISBhwA',\n"," 'employee_id': b'XQfwVwDr-v0ZS3_CbbE5Xw',\n"," 'stars': 3.0}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"P7sRtN9eY-Zj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's figure out **unique employee ids** and **customer ids** present in the data.\n","\n","This is important because we **need to be able to map the raw values of our categorical features to embedding vectors** in our models. To do that, we **need a vocabulary that maps a raw feature value to an integer in a contiguous range**: *this allows us to look up the corresponding embeddings in our embedding tables*."],"metadata":{"id":"aL-ZaGOBZYvd"}},{"cell_type":"code","source":["# Extracting & processing data to build vocabularies (for customer and employee embeddings)\n","\n","customers = tf_dataset.map(lambda x: x[\"customer_id\"])\n","employees = tf_dataset.map(lambda x: x[\"employee_id\"])\n","\n","customer_ids = customers.batch(1_000)\n","employee_ids = employees.batch(1_000)\n","\n","unique_customer_ids = np.unique(np.concatenate(list(customer_ids))) # vocabulary for the customer embeddings\n","unique_employee_ids = np.unique(np.concatenate(list(employee_ids))) # vocabulary for the employee embeddings"],"metadata":{"id":"S5X0qIOwZZNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unique_customer_ids[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkMPplowZd-W","executionInfo":{"status":"ok","timestamp":1736200294776,"user_tz":-330,"elapsed":13,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"73b3501a-b765-4331-bc5a-3a8313f4b06b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'---1lKK3aKOuomHnwAkAow', b'---2PmXbF47D870stH1jqA',\n","       b'---UgP94gokyCDuB5zUssA', b'---fa6ZK37T9NjkGKI4oSg',\n","       b'---r61b7EpVPkb4UVme5tA', b'---zemaUC8WeJeWKqS6p9Q',\n","       b'--034gGozmK4y5txuPsdAA', b'--0DrQkM0FT-yCQRWw82uQ',\n","       b'--0FNOzZkEQlz8WzS3WttQ', b'--0Jj_J_MmUJ51f1Y394Uw'], dtype=object)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["print(len(unique_customer_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlO_83GvZfl8","executionInfo":{"status":"ok","timestamp":1736200294776,"user_tz":-330,"elapsed":11,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"f92ff261-206d-4aa4-bc94-317bf9052451"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1987685\n"]}]},{"cell_type":"code","source":["unique_employee_ids[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EgNStoXrZhgM","executionInfo":{"status":"ok","timestamp":1736200294776,"user_tz":-330,"elapsed":9,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"9018b7e8-12f6-4a32-b2b1-e33fdfca0756"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'---kPU91CF4Lq2-WlRu9Lw', b'--0iUa4sNDFiZFrAdIWhZQ',\n","       b'--30_8IhuyMHbSOcNWd6DQ', b'--7PUidqRWpRSpXebiyxTg',\n","       b'--7jw19RH9JKXgFohspgQw', b'--8IbOsAAxjKRoYsBFL-PA',\n","       b'--9osgUCSDUWUkoTLdvYhQ', b'--ARBQr1WMsTWiwOKOj-FQ',\n","       b'--FWWsIwxRwuw9vIMImcQg', b'--FcbSxK1AoEtEAxOgBaCw'], dtype=object)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["print(len(unique_employee_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WO-6OfYIZjBE","executionInfo":{"status":"ok","timestamp":1736200294776,"user_tz":-330,"elapsed":8,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"fe750b4d-f6e2-43c2-b337-32a6ef60f212"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["150243\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3q_K36YIZlD1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split data into a training and evaluation set\n","# split the data by putting 80% of the ratings in the train set, and 20% in the test set.\n","\n","tf.random.set_seed(42)\n","shuffled = tf_dataset.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n","\n","'''FOLLWING IS NOT APPLICABLE FOR THIS MODEL 2'''\n","# Since this model is used only to recreate the already obtained overall ratings by the employees who are already in the production database,\n","# it is suitable to use the test dataset also for training to recreate their ratings as well.\n","# Because no unseen data are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data (unseen employees but not for unseen categories).\n","# Therefore, following code snippets to create train and test splits are ommitted during execution.\n","\n","# But if there is an employee who hasn't worked and received a rating yet, that employee will never be appeared in the recommendations and will never be able to get a work for herself/himself.\n","# Therefore, it is necessary to make this model generalise to unseen data which will enable such employees to appear in the recommendations to receive job opportunities for themselves.\n","# (e.g. If employee A has 0 rating [not worked], and if we have use all the train and test dataset to train, then the model will recreate that employee A has 0 rating.\n","# But if we try to generalise the model using a test set [not used to train], there is a possibility that employee A might receive a bit higher rating by the model.\n","# This possiblity will enable that employee to appear in recommendations to get a work for herself/himself).\n","# But this is not our purpose of this model, we just need to recreate the overall ratings of all the employees in our database. This avoids the need for requesting employee ratings from the database for millions of employees for each request done by the customer.\n","# Therefore, following code snippets to create train and test splits are ommitted during execution.\n","\n","trainset_size = round(len(shuffled) * 0.8)\n","testset_size = round(len(shuffled) * 0.2)\n","\n","train = shuffled.take(trainset_size)\n","test = shuffled.skip(trainset_size).take(testset_size)"],"metadata":{"id":"IxNZ4aimZmuc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Displaying a sample from the TensorFlow train Dataset using pprint\n","#for x in train.take(1).as_numpy_iterator():\n","#    pprint.pprint(x)"],"metadata":{"id":"dzPR_iFB9A1I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Displaying a sample from the TensorFlow test Dataset using pprint\n","#for x in test.take(1).as_numpy_iterator():\n","#    pprint.pprint(x)"],"metadata":{"id":"miOYaUw-0Ab2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implementing a model"],"metadata":{"id":"y_ipDXM8b0t9"}},{"cell_type":"markdown","source":["## Architecture\n","\n","Ranking models do not face the same efficiency constraints as retrieval models do, and so we have a little bit more freedom in our choice of architectures.\n","\n","A model composed of multiple stacked dense layers is a relatively common architecture for ranking tasks. We can implement it as follows:"],"metadata":{"id":"-RuDNJ-ob3GO"}},{"cell_type":"code","source":["class RankingModel(tf.keras.Model):\n","\n","  def __init__(self):\n","    super().__init__()\n","    embedding_dimension = 32 # The dimensionality of the customer and employees embeddings/representations\n","\n","    # Compute embeddings for customers.\n","    self.customer_embeddings = tf.keras.Sequential([\n","      tf.keras.layers.StringLookup(\n","        vocabulary=unique_customer_ids, mask_token=None),\n","      # We add an additional embedding to account for unknown tokens (to handle unseen or out-of-vocabulary (OOV) data.)\n","      tf.keras.layers.Embedding(len(unique_customer_ids) + 1, embedding_dimension)\n","    ])\n","\n","    # Compute embeddings for employees.\n","    self.employee_embeddings = tf.keras.Sequential([\n","      tf.keras.layers.StringLookup(\n","        vocabulary=unique_employee_ids, mask_token=None),\n","      # We add an additional embedding to account for unknown tokens (to handle unseen or out-of-vocabulary (OOV) data.)\n","      tf.keras.layers.Embedding(len(unique_employee_ids) + 1, embedding_dimension)\n","    ])\n","\n","    # Compute predictions.\n","    self.ratings = tf.keras.Sequential([\n","      # Learn multiple dense layers.\n","      tf.keras.layers.Dense(256, activation=\"relu\"),\n","      tf.keras.layers.Dense(64, activation=\"relu\"),\n","      # Make rating predictions in the final layer.\n","      tf.keras.layers.Dense(1)\n","  ])\n","\n","  def call(self, inputs):\n","\n","    customer_id, employee_id = inputs\n","\n","    customer_embedding = self.customer_embeddings(customer_id)\n","    employee_embedding = self.employee_embeddings(employee_id)\n","\n","    return self.ratings(tf.concat([customer_embedding, employee_embedding], axis=1))"],"metadata":{"id":"IU6yXjRvcBhN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This model takes customer ids and employee ids, and outputs a predicted rating:"],"metadata":{"id":"m4g4ToQMeV_G"}},{"cell_type":"code","source":["RankingModel()(([\"Ha3iJu77CxlrFm-vQRs_8g\"], [\"W0vdz23JQtVQX5vJkiCj3g\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C4YowCnTeWXH","executionInfo":{"status":"ok","timestamp":1736200420097,"user_tz":-330,"elapsed":7171,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"3961e142-5001-4da7-85af-46ac1e639400"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.01650509]], dtype=float32)>"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["## Loss and metrics\n","\n","The next component is the loss used to train our model. TFRS has several loss layers and tasks to make this easy.\n","\n","In this instance, we'll make use of the `Ranking` task object: a convenience wrapper that bundles together the loss function and metric computation.\n","\n","We'll use it together with the `MeanSquaredError` Keras loss in order to predict the ratings."],"metadata":{"id":"SU1yEhOOep0Q"}},{"cell_type":"code","source":["task = tfrs.tasks.Ranking(\n","  loss = tf.keras.losses.MeanSquaredError(),\n","  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",")"],"metadata":{"id":"7G8DCmlcez0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The task itself is a Keras layer that takes true and predicted as arguments, and returns the computed loss. We'll use that to implement the model's training loop."],"metadata":{"id":"YtbA4MQme2lG"}},{"cell_type":"markdown","source":["## The full model\n","\n","We can now put it all together into a model. TFRS exposes a base model class (`tfrs.models.Model`) which streamlines bulding models: all we need to do is to set up the components in the `__init__` method, and implement the `compute_loss` method, taking in the raw features and returning a loss value.\n","\n","The base model will then take care of creating the appropriate training loop to fit our model."],"metadata":{"id":"uNMrqebNe83O"}},{"cell_type":"code","source":["class YelpModel(tfrs.models.Model):\n","\n","  def __init__(self):\n","    super().__init__()\n","    self.ranking_model: tf.keras.Model = RankingModel()\n","    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n","      loss = tf.keras.losses.MeanSquaredError(),\n","      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n","    )\n","\n","  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n","    return self.ranking_model(\n","        (features[\"customer_id\"], features[\"employee_id\"]))\n","\n","  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n","    labels = features.pop(\"stars\")\n","\n","    rating_predictions = self(features)\n","\n","    # The task computes the loss and the metrics.\n","    return self.task(labels=labels, predictions=rating_predictions)"],"metadata":{"id":"OdIlY1l2fCwO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fitting and evaluating\n","\n","After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model.\n","\n","Let's first instantiate the model."],"metadata":{"id":"uWuHC4ZmgVt3"}},{"cell_type":"code","source":["model = YelpModel()\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"],"metadata":{"id":"NLK3CzChgYoe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then shuffle, batch, and cache the training and evaluation data."],"metadata":{"id":"YoLHTnwVgd6G"}},{"cell_type":"code","source":["'''FOLLWING IS NOT APPLICABLE FOR THIS MODEL 2'''\n","# Since this model is used only to recreate the already obtained overall ratings by the employees who are already in the production database,\n","# it is suitable to use the test dataset also for training to recreate their ratings as well.\n","# Because no unseen data are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data (unseen employees but not for unseen categories).\n","# We just need to recreate the overall ratings of all the employees in our database. This avoids the need for requesting employee ratings from the database for millions of employees for each request done by the customer.\n","# Therefore, following code snippets to create train and test splits are ommitted during execution.\n","\n","cached_train = train.shuffle(100_000).batch(8192).cache()\n","cached_test = test.batch(4096).cache()\n","\n","#cached_train = shuffled.shuffle(100_000).batch(8192).cache()"],"metadata":{"id":"0b0y8w3hgeXi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then train the  model:"],"metadata":{"id":"c1RTwqFegh6v"}},{"cell_type":"code","source":["model.fit(cached_train, epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVODSxLdgj9e","executionInfo":{"status":"ok","timestamp":1736204207442,"user_tz":-330,"elapsed":2701904,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"f631249c-1b57-4972-bc79-6f0052af4ef7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","683/683 [==============================] - 46s 65ms/step - root_mean_squared_error: 1.4596 - loss: 2.1304 - regularization_loss: 0.0000e+00 - total_loss: 2.1304\n","Epoch 2/50\n","683/683 [==============================] - 44s 64ms/step - root_mean_squared_error: 1.3613 - loss: 1.8531 - regularization_loss: 0.0000e+00 - total_loss: 1.8531\n","Epoch 3/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 1.3228 - loss: 1.7498 - regularization_loss: 0.0000e+00 - total_loss: 1.7498\n","Epoch 4/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 1.3074 - loss: 1.7092 - regularization_loss: 0.0000e+00 - total_loss: 1.7092\n","Epoch 5/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.2984 - loss: 1.6858 - regularization_loss: 0.0000e+00 - total_loss: 1.6858\n","Epoch 6/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.2911 - loss: 1.6667 - regularization_loss: 0.0000e+00 - total_loss: 1.6667\n","Epoch 7/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.2834 - loss: 1.6469 - regularization_loss: 0.0000e+00 - total_loss: 1.6469\n","Epoch 8/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 1.2745 - loss: 1.6241 - regularization_loss: 0.0000e+00 - total_loss: 1.6241\n","Epoch 9/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.2639 - loss: 1.5971 - regularization_loss: 0.0000e+00 - total_loss: 1.5971\n","Epoch 10/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.2512 - loss: 1.5652 - regularization_loss: 0.0000e+00 - total_loss: 1.5652\n","Epoch 11/50\n","683/683 [==============================] - 43s 64ms/step - root_mean_squared_error: 1.2363 - loss: 1.5279 - regularization_loss: 0.0000e+00 - total_loss: 1.5279\n","Epoch 12/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 1.2187 - loss: 1.4848 - regularization_loss: 0.0000e+00 - total_loss: 1.4848\n","Epoch 13/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.1986 - loss: 1.4359 - regularization_loss: 0.0000e+00 - total_loss: 1.4359\n","Epoch 14/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 1.1758 - loss: 1.3818 - regularization_loss: 0.0000e+00 - total_loss: 1.3818\n","Epoch 15/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.1509 - loss: 1.3237 - regularization_loss: 0.0000e+00 - total_loss: 1.3237\n","Epoch 16/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.1246 - loss: 1.2639 - regularization_loss: 0.0000e+00 - total_loss: 1.2639\n","Epoch 17/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 1.0988 - loss: 1.2067 - regularization_loss: 0.0000e+00 - total_loss: 1.2067\n","Epoch 18/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.0759 - loss: 1.1567 - regularization_loss: 0.0000e+00 - total_loss: 1.1567\n","Epoch 19/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.0577 - loss: 1.1179 - regularization_loss: 0.0000e+00 - total_loss: 1.1179\n","Epoch 20/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 1.0436 - loss: 1.0885 - regularization_loss: 0.0000e+00 - total_loss: 1.0885\n","Epoch 21/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 1.0325 - loss: 1.0653 - regularization_loss: 0.0000e+00 - total_loss: 1.0653\n","Epoch 22/50\n","683/683 [==============================] - 44s 64ms/step - root_mean_squared_error: 1.0225 - loss: 1.0449 - regularization_loss: 0.0000e+00 - total_loss: 1.0449\n","Epoch 23/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 1.0136 - loss: 1.0267 - regularization_loss: 0.0000e+00 - total_loss: 1.0267\n","Epoch 24/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 1.0049 - loss: 1.0091 - regularization_loss: 0.0000e+00 - total_loss: 1.0091\n","Epoch 25/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.9968 - loss: 0.9929 - regularization_loss: 0.0000e+00 - total_loss: 0.9929\n","Epoch 26/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.9887 - loss: 0.9768 - regularization_loss: 0.0000e+00 - total_loss: 0.9768\n","Epoch 27/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.9806 - loss: 0.9609 - regularization_loss: 0.0000e+00 - total_loss: 0.9609\n","Epoch 28/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 0.9726 - loss: 0.9452 - regularization_loss: 0.0000e+00 - total_loss: 0.9452\n","Epoch 29/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 0.9645 - loss: 0.9296 - regularization_loss: 0.0000e+00 - total_loss: 0.9296\n","Epoch 30/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.9562 - loss: 0.9137 - regularization_loss: 0.0000e+00 - total_loss: 0.9137\n","Epoch 31/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.9478 - loss: 0.8976 - regularization_loss: 0.0000e+00 - total_loss: 0.8976\n","Epoch 32/50\n","683/683 [==============================] - 45s 66ms/step - root_mean_squared_error: 0.9391 - loss: 0.8813 - regularization_loss: 0.0000e+00 - total_loss: 0.8813\n","Epoch 33/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 0.9301 - loss: 0.8645 - regularization_loss: 0.0000e+00 - total_loss: 0.8645\n","Epoch 34/50\n","683/683 [==============================] - 45s 66ms/step - root_mean_squared_error: 0.9205 - loss: 0.8466 - regularization_loss: 0.0000e+00 - total_loss: 0.8466\n","Epoch 35/50\n","683/683 [==============================] - 44s 64ms/step - root_mean_squared_error: 0.9105 - loss: 0.8284 - regularization_loss: 0.0000e+00 - total_loss: 0.8284\n","Epoch 36/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 0.8997 - loss: 0.8088 - regularization_loss: 0.0000e+00 - total_loss: 0.8088\n","Epoch 37/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 0.8885 - loss: 0.7888 - regularization_loss: 0.0000e+00 - total_loss: 0.7888\n","Epoch 38/50\n","683/683 [==============================] - 44s 64ms/step - root_mean_squared_error: 0.8764 - loss: 0.7675 - regularization_loss: 0.0000e+00 - total_loss: 0.7675\n","Epoch 39/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.8638 - loss: 0.7456 - regularization_loss: 0.0000e+00 - total_loss: 0.7456\n","Epoch 40/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 0.8509 - loss: 0.7234 - regularization_loss: 0.0000e+00 - total_loss: 0.7234\n","Epoch 41/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 0.8377 - loss: 0.7011 - regularization_loss: 0.0000e+00 - total_loss: 0.7011\n","Epoch 42/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.8244 - loss: 0.6790 - regularization_loss: 0.0000e+00 - total_loss: 0.6790\n","Epoch 43/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 0.8108 - loss: 0.6569 - regularization_loss: 0.0000e+00 - total_loss: 0.6569\n","Epoch 44/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.7971 - loss: 0.6348 - regularization_loss: 0.0000e+00 - total_loss: 0.6348\n","Epoch 45/50\n","683/683 [==============================] - 44s 64ms/step - root_mean_squared_error: 0.7833 - loss: 0.6131 - regularization_loss: 0.0000e+00 - total_loss: 0.6131\n","Epoch 46/50\n","683/683 [==============================] - 43s 63ms/step - root_mean_squared_error: 0.7701 - loss: 0.5926 - regularization_loss: 0.0000e+00 - total_loss: 0.5926\n","Epoch 47/50\n","683/683 [==============================] - 44s 65ms/step - root_mean_squared_error: 0.7568 - loss: 0.5722 - regularization_loss: 0.0000e+00 - total_loss: 0.5722\n","Epoch 48/50\n","683/683 [==============================] - 45s 66ms/step - root_mean_squared_error: 0.7437 - loss: 0.5526 - regularization_loss: 0.0000e+00 - total_loss: 0.5526\n","Epoch 49/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 0.7308 - loss: 0.5335 - regularization_loss: 0.0000e+00 - total_loss: 0.5335\n","Epoch 50/50\n","683/683 [==============================] - 45s 65ms/step - root_mean_squared_error: 0.7183 - loss: 0.5155 - regularization_loss: 0.0000e+00 - total_loss: 0.5155\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf_keras.src.callbacks.History at 0x7b8cd70868f0>"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["As the model trains, the loss is falling and the RMSE metric is improving."],"metadata":{"id":"wLv3rAL6glsR"}},{"cell_type":"markdown","source":["Finally, we can evaluate our model on the test set:"],"metadata":{"id":"E-l6KGEAgoMn"}},{"cell_type":"code","source":["'''FOLLWING IS NOT APPLICABLE FOR THIS MODEL 2'''\n","# Since this model is used only to recreate the already obtained overall ratings by the employees who are already in the production database,\n","# it is suitable to use the test dataset also for training to recreate their ratings as well.\n","# Because no unseen data are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data (unseen employees but not for unseen categories).\n","# We just need to recreate the overall ratings of all the employees in our database. This avoids the need for requesting employee ratings from the database for millions of employees for each request done by the customer.\n","# Therefore, following code snippet to test the model is ommitted during execution.\n","\n","model.evaluate(cached_test, return_dict=True)"],"metadata":{"id":"KFk93dNigqnu","executionInfo":{"status":"ok","timestamp":1736204288612,"user_tz":-330,"elapsed":4165,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b73ee9d-b477-4d5c-bbda-c07a4dc5a052"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["342/342 [==============================] - 4s 11ms/step - root_mean_squared_error: 1.7364 - loss: 3.0178 - regularization_loss: 0.0000e+00 - total_loss: 3.0178\n"]},{"output_type":"execute_result","data":{"text/plain":["{'root_mean_squared_error': 1.7364033460617065,\n"," 'loss': 3.5482215881347656,\n"," 'regularization_loss': 0,\n"," 'total_loss': 3.5482215881347656}"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["The lower the RMSE metric, the more accurate our model is at predicting ratings."],"metadata":{"id":"DGfhKu-ggs2o"}},{"cell_type":"code","source":[],"metadata":{"id":"LwfY5Jclgu_-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing the ranking model\n","\n","Now we can test the ranking model by computing predictions for a set of employees and then rank these employees based on the predictions:\n"],"metadata":{"id":"jATkZABNoPv6"}},{"cell_type":"code","source":["test_ratings = {}\n","test_employee_ids = [\"YbnJYHNp_fHbI-hcFg48vQ\", \"DD3TxygdxBxKh9gbjCuLDA\", \"1bJxvwuMTyXmQGu90WLPhA\", \"W0vdz23JQtVQX5vJkiCj3g\", \"lTCoYu00AUV0SHxOa-XXBw\"]\n","for employee_id in test_employee_ids:\n","  test_ratings[employee_id] = model({\n","      \"customer_id\": np.array([\"Ha3iJu77CxlrFm-vQRs_8g\"]),\n","      \"employee_id\": np.array([employee_id])\n","  })\n","\n","print(\"Ratings:\")\n","for employee_id, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n","  print(f\"{employee_id}: {score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGveMSVtoQ50","executionInfo":{"status":"ok","timestamp":1736205124647,"user_tz":-330,"elapsed":1054,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"d202b86f-86ee-4086-d350-17681523b194"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ratings:\n","YbnJYHNp_fHbI-hcFg48vQ: [[4.92117]]\n","lTCoYu00AUV0SHxOa-XXBw: [[4.74607]]\n","DD3TxygdxBxKh9gbjCuLDA: [[4.2790422]]\n","1bJxvwuMTyXmQGu90WLPhA: [[1.313463]]\n","W0vdz23JQtVQX5vJkiCj3g: [[1.1837858]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"P5znfkHBqTrt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exporting for serving\n","\n","The model can be easily exported for serving:\n"],"metadata":{"id":"ReBBCSIUqULr"}},{"cell_type":"code","source":["tf.saved_model.save(model, \"export\")"],"metadata":{"id":"fOh9WaWiqZ16"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can now load it back and perform predictions:"],"metadata":{"id":"9cFegSG4qdsp"}},{"cell_type":"code","source":["loaded = tf.saved_model.load(\"export\")\n","\n","loaded({\"customer_id\": np.array([\"Ha3iJu77CxlrFm-vQRs_8g\"]), \"employee_id\": [\"DD3TxygdxBxKh9gbjCuLDA\"]}).numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PZmrvInqqeHj","executionInfo":{"status":"ok","timestamp":1736205315047,"user_tz":-330,"elapsed":2434,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"3c80f87d-9952-4485-b885-cd3a506a524c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4.2790422]], dtype=float32)"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":[],"metadata":{"id":"EmEzelUiJUSl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the folder path for saving the model\n","save_dir = '/content/drive/My Drive/Colab Notebooks/Saved Models'\n","#save_dir = '/content/Saved Model'\n","\n","# Ensure the folder exists\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# Path to save the model\n","model_path = os.path.join(save_dir, \"recsys_model_two_ranking\")\n","\n","# Save the model\n","tf.saved_model.save(\n","    model,\n","    model_path\n",")\n","\n","# Load the model back\n","loaded = tf.saved_model.load(model_path)\n","\n","# Pass a customer id name and employee id to get rating predictions\n","rating = loaded({\"customer_id\": np.array([\"Ha3iJu77CxlrFm-vQRs_8g\"]), \"employee_id\": [\"DD3TxygdxBxKh9gbjCuLDA\"]}).numpy()\n","\n","print(\"Rating predictions:\")\n","print(f\"DD3TxygdxBxKh9gbjCuLDA: {rating[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEcTaGMzr-mz","executionInfo":{"status":"ok","timestamp":1736205440488,"user_tz":-330,"elapsed":122757,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"8684ce1f-4c2f-4263-8bc4-2682ee8fbb91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Rating predictions:\n","DD3TxygdxBxKh9gbjCuLDA: [4.2790422]\n"]}]}]}