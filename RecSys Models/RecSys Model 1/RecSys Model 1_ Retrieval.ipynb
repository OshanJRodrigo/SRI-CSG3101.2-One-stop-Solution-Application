{"cells":[{"cell_type":"markdown","source":["References: https://www.tensorflow.org/recommenders/examples/basic_retrieval"],"metadata":{"id":"uV_yMabn4R0P"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgh7h9orWW8V"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# **RecSys Model 1: Retrieval**"],"metadata":{"id":"QQTUHJR8R2OO"}},{"cell_type":"markdown","source":["Real-world recommender systems are often composed of two stages:\n","\n","1.   **The retrieval stage** is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient.\n","\n","2.   **The ranking stage** takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.\n","\n","In this notebook, we're going to build the first stage, retrieval."],"metadata":{"id":"XH11XMmKQwfP"}},{"cell_type":"code","source":[],"metadata":{"id":"jhaSYLF8RViA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Retrieval models are often composed of two sub-models:\n","\n","1.   **A query model** computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n","\n","2.   **A candidate model** computing the candidate representation (an equally-sized vector) using the candidate features\n","\n","The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query."],"metadata":{"id":"vJfei8CmRas-"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"UMQb_WniLfXU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42784,"status":"ok","timestamp":1736087667993,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"RPz_0jFAJOYz","outputId":"166fec4a-6e72-4dfb-a911-4c566aac95e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.17.1\n","Uninstalling tensorflow-2.17.1:\n","  Successfully uninstalled tensorflow-2.17.1\n","\u001b[33mWARNING: Skipping tensorflow-recommenders as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: tensorflow-datasets 4.9.7\n","Uninstalling tensorflow-datasets-4.9.7:\n","  Successfully uninstalled tensorflow-datasets-4.9.7\n"]}],"source":["# Temporary solution for a bug in the implementation of the tfrs.layers.factorized_top_k module.\n","# https://github.com/tensorflow/recommenders/issues/712#issuecomment-2041163592\n","\n","!pip uninstall tensorflow -y\n","!pip uninstall tensorflow-recommenders -y\n","#!pip uninstall tensorflow-datasets -y\n","\n","\n","import os\n","os.environ['TF_USE_LEGACY_KERAS'] = '1'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57770,"status":"ok","timestamp":1736087725758,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"8waSiZGeJXto","outputId":"d6c97acb-898b-4e4d-c103-1365a89f8268"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q tensorflow==2.17\n","!pip install -q tensorflow-recommenders==0.7.3\n","\n","#!pip install -q --upgrade tensorflow-datasets\n","!pip install -q scann"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwHdgKCbJcGQ"},"outputs":[],"source":["import pprint\n","import tempfile\n","\n","from typing import Dict, Text\n","\n","import numpy as np\n","import tensorflow as tf\n","#import tensorflow_datasets as tfds\n","\n","#import json\n","import pandas as pd\n","from google.colab import drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60EKmiAfJaGo"},"outputs":[],"source":["import tensorflow_recommenders as tfrs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1736087733726,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"whJJiPhfJgYo","outputId":"01e684b6-df77-468f-b883-decf731c6053"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.17.0\n"]}],"source":["print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1736087733726,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"8mu8sjB8Jh9w","outputId":"c8908810-86e3-4230-9184-3d7b74104508"},"outputs":[{"output_type":"stream","name":"stdout","text":["v0.7.3\n"]}],"source":["print(tfrs.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Maq9iMa_NsZJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7bvRaxyBNt85"},"source":["# Importing and preprocessing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24244,"status":"ok","timestamp":1736087757962,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"-yDH0GPQNlix","outputId":"ee570a24-f760-48c7-e7b0-79d943469b16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGH_OmtFNpeC"},"outputs":[],"source":["JSON_FILE = '/content/drive/My Drive/yelp_academic_dataset_business.json'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12009,"status":"ok","timestamp":1736087769966,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"lnJZM2LJJl3I","outputId":"3a1844d1-f2f3-4d18-d460-2e9985858d7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["              business_id                      name  \\\n","0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n","1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n","2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n","3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n","4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n","\n","                           address           city state postal_code  \\\n","0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n","1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n","2             5255 E Broadway Blvd         Tucson    AZ       85711   \n","3                      935 Race St   Philadelphia    PA       19107   \n","4                    101 Walnut St     Green Lane    PA       18054   \n","\n","    latitude   longitude  stars  review_count  is_open  \\\n","0  34.426679 -119.711197    5.0             7        0   \n","1  38.551126  -90.335695    3.0            15        1   \n","2  32.223236 -110.880452    3.5            22        0   \n","3  39.955505  -75.155564    4.0            80        1   \n","4  40.338183  -75.471659    4.5            13        1   \n","\n","                                          attributes  \\\n","0                      {'ByAppointmentOnly': 'True'}   \n","1             {'BusinessAcceptsCreditCards': 'True'}   \n","2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n","3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n","4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n","\n","                                          categories  \\\n","0  Doctors, Traditional Chinese Medicine, Naturop...   \n","1  Shipping Centers, Local Services, Notaries, Ma...   \n","2  Department Stores, Shopping, Fashion, Home & G...   \n","3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n","4                          Brewpubs, Breweries, Food   \n","\n","                                               hours  \n","0                                               None  \n","1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n","2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n","3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n","4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  \n"]}],"source":["# Define the number of lines to read\n","#n_lines = 25000\n","\n","# Read the specified number of lines into a list of dictionaries\n","#with open(JSON_FILE, \"r\") as file:\n","#    data = [json.loads(next(file)) for _ in range(n_lines)]\n","\n","# Read the JSON lines file directly into a pandas DataFrame\n","df = pd.read_json(JSON_FILE, lines=True)\n","\n","# Convert the list of dictionaries into a DataFrame\n","#df = pd.DataFrame(data)\n","\n","# Display the first few rows\n","print(df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1736087769966,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"Z8E-VAZ6TOLb","outputId":"2678f2de-71ad-4b82-bd12-22d1e2e9e751"},"outputs":[{"output_type":"stream","name":"stdout","text":["150346\n"]}],"source":["print(len(df)) # total number of entries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1736087769966,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"hXrDfS0jOrAL","outputId":"de9ccfa3-5c5d-49d4-b907-f28b8fce6e4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                          categories             business_id  \\\n","0  Doctors, Traditional Chinese Medicine, Naturop...  Pns2l4eNsfO8kk83dixA6A   \n","1  Shipping Centers, Local Services, Notaries, Ma...  mpf3x-BjTdTEA3yCZrAYPw   \n","2  Department Stores, Shopping, Fashion, Home & G...  tUFrWirKiKi_TAnsVWINQQ   \n","3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...  MTSW4McQd7CbVtyjqoe9mw   \n","4                          Brewpubs, Breweries, Food  mWMc6_wTdE0EUBKIGXDVfA   \n","\n","   stars  \n","0    5.0  \n","1    3.0  \n","2    3.5  \n","3    4.0  \n","4    4.5  \n"]}],"source":["# Filter rows where 'categories' is not null\n","df = df[df['categories'].notnull()]\n","\n","# Select specific columns\n","df = df[['categories', 'business_id', 'stars']]\n","\n","# Display the result\n","print(df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1736087769966,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"bGwBVvFkPRCC","outputId":"046e7046-66b0-41a8-808b-6fb96284622b"},"outputs":[{"output_type":"stream","name":"stdout","text":["150243\n"]}],"source":["print(len(df))  # number of entries after removing 103 rows where 'categories' have null value"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1135,"status":"ok","timestamp":1736087771094,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"d-46vcEnQ5a0","outputId":"7e337686-62ae-4a2f-e4a3-131e8107d097"},"outputs":[{"output_type":"stream","name":"stdout","text":["                       category             employee_id  overall_star\n","0                       Doctors  Pns2l4eNsfO8kk83dixA6A           5.0\n","1  Traditional Chinese Medicine  Pns2l4eNsfO8kk83dixA6A           5.0\n","2         Naturopathic/Holistic  Pns2l4eNsfO8kk83dixA6A           5.0\n","3                   Acupuncture  Pns2l4eNsfO8kk83dixA6A           5.0\n","4              Health & Medical  Pns2l4eNsfO8kk83dixA6A           5.0\n"]}],"source":["# Split 'categories' into a list of categories\n","df['categories'] = df['categories'].str.split(', ')\n","\n","# Use explode to create a row for each category\n","df = df.explode('categories').reset_index(drop=True)\n","\n","# Rename columns\n","df = df.rename(columns={'categories': 'category', 'business_id': 'employee_id', 'stars': 'overall_star'})\n","\n","# Display the result\n","print(df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1736087771094,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"Wa3ikSkDhCkg","outputId":"fb61a0c9-c6d7-4030-f59c-9bbc1b16913a"},"outputs":[{"output_type":"stream","name":"stdout","text":["668592\n"]}],"source":["print(len(df)) # total number of entries after splitting 'categories'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_oSCDw9ZRsn"},"outputs":[],"source":["# Create TensorFlow Dataset using tf.data\n","tf_dataset = tf.data.Dataset.from_tensor_slices((\n","    {'category': df['category'].astype(str).values,      # Ensure conversion to strings\n","    'employee_id': df['employee_id'].astype(str).values,   # Ensure conversion to strings\n","    'overall_star': df['overall_star'].astype(float).values}  # Ensure conversion to floats\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1736087773360,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"yrJnXLJ8ZvNO","outputId":"e6e12639-93bc-43b2-9b4b-1c190d0960ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'category': b'Doctors',\n"," 'employee_id': b'Pns2l4eNsfO8kk83dixA6A',\n"," 'overall_star': 5.0}\n"]}],"source":["# Displaying a sample from the TensorFlow Dataset using pprint\n","for x in tf_dataset.take(1).as_numpy_iterator():\n","    pprint.pprint(x)"]},{"cell_type":"code","source":[],"metadata":{"id":"NKteMRn5TrM3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's figure out **unique employee ids** and **categories** present in the data.\n","\n","This is important because we **need to be able to map the raw values of our categorical features to embedding vectors** in our models. To do that, we **need a vocabulary that maps a raw feature value to an integer in a contiguous range**: *this allows us to look up the corresponding embeddings in our embedding tables*."],"metadata":{"id":"137IhtXeTV9e"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"csradRD3JK_R"},"outputs":[],"source":["# Extracting & processing data to build vocabularies (for query and candidate towers)\n","\n","employees = tf_dataset.map(lambda x: x[\"employee_id\"])\n","categories = tf_dataset.map(lambda x: x[\"category\"])\n","\n","employee_ids = employees.batch(1_000)\n","category_names = categories.batch(1_000)\n","\n","unique_employee_ids = np.unique(np.concatenate(list(employee_ids))) # vocabulary for the candidate tower\n","unique_category_names = np.unique(np.concatenate(list(category_names))) # vocabulary for the query tower"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1736087790629,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"nB_e4lGuKTZx","outputId":"d0ebadcc-77e5-45f9-8cf3-49ea6c57c6a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'---kPU91CF4Lq2-WlRu9Lw', b'--0iUa4sNDFiZFrAdIWhZQ',\n","       b'--30_8IhuyMHbSOcNWd6DQ', b'--7PUidqRWpRSpXebiyxTg',\n","       b'--7jw19RH9JKXgFohspgQw', b'--8IbOsAAxjKRoYsBFL-PA',\n","       b'--9osgUCSDUWUkoTLdvYhQ', b'--ARBQr1WMsTWiwOKOj-FQ',\n","       b'--FWWsIwxRwuw9vIMImcQg', b'--FcbSxK1AoEtEAxOgBaCw'], dtype=object)"]},"metadata":{},"execution_count":18}],"source":["unique_employee_ids[:10]"]},{"cell_type":"code","source":["print(len(unique_employee_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGHNT7TVegd6","executionInfo":{"status":"ok","timestamp":1736087790629,"user_tz":-330,"elapsed":14,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"79dc1eb0-329d-4fa0-920f-ca8cf73799e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["150243\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1736087790629,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"tmOUySNPKVND","outputId":"218bed6d-2b8c-4291-c9f6-146c9886b077"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'& Probates', b'3D Printing', b'ATV Rentals/Tours', b'Acai Bowls',\n","       b'Accessories', b'Accountants', b'Acne Treatment', b'Active Life',\n","       b'Acupuncture', b'Addiction Medicine'], dtype=object)"]},"metadata":{},"execution_count":20}],"source":["unique_category_names[:10]"]},{"cell_type":"code","source":["print(len(unique_category_names))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Deb8HV6aT9-P","executionInfo":{"status":"ok","timestamp":1736087790629,"user_tz":-330,"elapsed":10,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"0481fed0-886e-4433-a9ee-ffc04eca9fcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1311\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3_xKBYrKelj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2nee8htWeq0Q"},"outputs":[],"source":["# Data to train/test the model\n","tf_dataset = tf_dataset.map(lambda x: {\n","    \"employee_id\": x[\"employee_id\"],\n","    \"category\": x[\"category\"],\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yaz3vE1AHTMY"},"outputs":[],"source":["# Split data into a training and evaluation set\n","\n","tf.random.set_seed(42)\n","shuffled = tf_dataset.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n","\n","# Since this model creates just a retrival index, it is suitable to use the test dataset also for training to index them as well.\n","# Because no unseen data/queries are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data.\n","# Therefore, following code snippets to create train and test splits are ommitted during execution.\n","\n","#trainset_size = round(len(shuffled) * 0.8)\n","#testset_size = round(len(shuffled) * 0.2)\n","\n","#train = shuffled.take(trainset_size)\n","#test = shuffled.skip(trainset_size).take(testset_size)"]},{"cell_type":"markdown","metadata":{"id":"oHeilbgtMHLq"},"source":["# Implementing a model\n"," A two-tower retrieval model, we can build each tower separately and then combine them in the final model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IcQlJZGMNox"},"outputs":[],"source":["# The dimensionality of the query and candidate representations\n","embedding_dimension = 32"]},{"cell_type":"markdown","metadata":{"id":"IqpvJNbKMOzB"},"source":["## The query tower\n","A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n","\n","\n"," Use Keras preprocessing layers to first convert category names to integers, and then convert those to category name embeddings via an `Embedding` layer. Note that we use the list of unique category names we computed earlier as a vocabulary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1zdEThnMVmL"},"outputs":[],"source":["category_model = tf.keras.Sequential([\n","  tf.keras.layers.StringLookup(\n","      vocabulary=unique_category_names, mask_token=None),\n","  # We add an additional embedding to account for unknown tokens (to handle unseen or out-of-vocabulary (OOV) data.)\n","  tf.keras.layers.Embedding(len(unique_category_names) + 1, embedding_dimension)\n","])"]},{"cell_type":"markdown","metadata":{"id":"rWfrCS2QM3-6"},"source":["## The candidate tower\n","A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n","\n"," Use Keras preprocessing layers to first convert employee ids to integers, and then convert those to employee id embeddings via an `Embedding` layer. Note that we use the list of unique employee ids we computed earlier as a vocabulary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mKJyyy-MM5F7"},"outputs":[],"source":["employee_model = tf.keras.Sequential([\n","  tf.keras.layers.StringLookup(\n","      vocabulary=unique_employee_ids, mask_token=None),\n","  # We add an additional embedding to account for unknown tokens (to handle unseen or out-of-vocabulary (OOV) data.)\n","  tf.keras.layers.Embedding(len(unique_employee_ids) + 1, embedding_dimension)\n","])"]},{"cell_type":"markdown","metadata":{"id":"QVkZmj_bNZQq"},"source":["## Metrics\n","\n","In our training data we have positive (category, employee) pairs. To figure out how good our model is, we need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates: if the score for the positive pair is higher than for all other candidates, our model is highly accurate.\n","\n","To do this, we can use the `tfrs.metrics.FactorizedTopK metric`. The metric has one required argument: the dataset of candidates that are used as implicit negatives for evaluation.\n","\n","In our case, that's the employee ids dataset, converted into embeddings via our employee model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"idG8KHIZNaCj"},"outputs":[],"source":["metrics = tfrs.metrics.FactorizedTopK(\n","  candidates=employees.batch(128).map(employee_model)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkTU6h6rOIfC"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ffmj0RoxOIu7"},"source":["## Loss\n","\n","The next component is the loss used to train our model. TFRS has several loss layers and tasks to make this easy.\n","\n","In this instance, we'll make use of the Retrieval task object: a convenience wrapper that bundles together the loss function and metric computation:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1I8uU7haOJkb"},"outputs":[],"source":["task = tfrs.tasks.Retrieval(\n","  metrics=metrics\n",")"]},{"cell_type":"markdown","source":["The task itself is a Keras layer that takes the query and candidate embeddings as arguments, and returns the computed loss: we'll use that to implement the model's training loop."],"metadata":{"id":"_gbt8BgNYP6B"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jt7DKFnxOmSH"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yjV3Z9WuOmbW"},"source":["## The full model\n","\n","We can now put it all together into a model. TFRS exposes a base model class (`tfrs.models.Model`) which streamlines building models: all we need to do is to set up the components in the` __init__` method, and implement the compute_loss method, taking in the raw features and returning a loss value.\n","\n","The base model will then take care of creating the appropriate training loop to fit our model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_I1SyMenOnd6"},"outputs":[],"source":["class YelpModel(tfrs.Model):\n","\n","  def __init__(self, category_model, employee_model):\n","    super().__init__()\n","    self.employee_model: tf.keras.Model = employee_model\n","    self.category_model: tf.keras.Model = category_model\n","    self.task: tf.keras.layers.Layer = task\n","\n","  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n","    # We pick out the category features and pass them into the category model.\n","    category_embeddings = self.category_model(features[\"category\"])\n","    # And pick out the employee features and pass them into the employee model,\n","    # getting embeddings back.\n","    positive_employee_embeddings = self.employee_model(features[\"employee_id\"])\n","\n","    if training:\n","      # The task computes the loss and not the metrics during training to speed up the process.\n","      return self.task(category_embeddings, positive_employee_embeddings, compute_metrics=False)\n","\n","\n","    # The task computes the loss and the metrics.\n","    return self.task(category_embeddings, positive_employee_embeddings)"]},{"cell_type":"markdown","source":["The `tfrs.Model` base class is a simply convenience class: it allows us to compute both training and test losses using the same method."],"metadata":{"id":"ibYeksErYpPR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjKSbhEjP6RD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5oaknpX7P6aD"},"source":["# Fitting and evaluating\n","\n","After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model.\n","\n","Let's first instantiate the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6zWRWDSP7LT"},"outputs":[],"source":["model = YelpModel(category_model, employee_model)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"]},{"cell_type":"markdown","source":["Then shuffle, batch, and cache the training and evaluation data"],"metadata":{"id":"iW83Dg9ZZkzc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMFzJ_vKQF37"},"outputs":[],"source":["# Since this model creates just a retrival index, it is suitable to use the test dataset also for training to index them as well.\n","# Because no unseen data/queries are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data.\n","# Therefore, following code snippets to create train and test splits are ommitted during execution.\n","\n","#cached_train = train.shuffle(100_000).batch(8192).cache()\n","#cached_test = test.batch(4096).cache()\n","\n","cached_train = shuffled.shuffle(100_000).batch(8192).cache()"]},{"cell_type":"markdown","source":["Then train the model:"],"metadata":{"id":"yBfIajDvZn2y"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509886,"status":"ok","timestamp":1736088302463,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"},"user_tz":-330},"id":"SQLHmWpfQG0D","outputId":"470857e3-3524-4eec-9587-4aff41552d4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","82/82 [==============================] - 28s 259ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 66444.6565 - regularization_loss: 0.0000e+00 - total_loss: 66444.6565\n","Epoch 2/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 55561.7436 - regularization_loss: 0.0000e+00 - total_loss: 55561.7436\n","Epoch 3/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51703.9627 - regularization_loss: 0.0000e+00 - total_loss: 51703.9627\n","Epoch 4/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49782.1013 - regularization_loss: 0.0000e+00 - total_loss: 49782.1013\n","Epoch 5/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48520.5904 - regularization_loss: 0.0000e+00 - total_loss: 48520.5904\n","Epoch 6/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 47656.0152 - regularization_loss: 0.0000e+00 - total_loss: 47656.0152\n","Epoch 7/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 47017.9263 - regularization_loss: 0.0000e+00 - total_loss: 47017.9263\n","Epoch 8/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 46531.0418 - regularization_loss: 0.0000e+00 - total_loss: 46531.0418\n","Epoch 9/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 46153.5991 - regularization_loss: 0.0000e+00 - total_loss: 46153.5991\n","Epoch 10/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 45846.6380 - regularization_loss: 0.0000e+00 - total_loss: 45846.6380\n","Epoch 11/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 45597.3492 - regularization_loss: 0.0000e+00 - total_loss: 45597.3492\n","Epoch 12/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 45388.5248 - regularization_loss: 0.0000e+00 - total_loss: 45388.5248\n","Epoch 13/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 45212.5704 - regularization_loss: 0.0000e+00 - total_loss: 45212.5704\n","Epoch 14/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 45061.0019 - regularization_loss: 0.0000e+00 - total_loss: 45061.0019\n","Epoch 15/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44930.2332 - regularization_loss: 0.0000e+00 - total_loss: 44930.2332\n","Epoch 16/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44815.3312 - regularization_loss: 0.0000e+00 - total_loss: 44815.3312\n","Epoch 17/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44714.1059 - regularization_loss: 0.0000e+00 - total_loss: 44714.1059\n","Epoch 18/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44623.7392 - regularization_loss: 0.0000e+00 - total_loss: 44623.7392\n","Epoch 19/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44542.9360 - regularization_loss: 0.0000e+00 - total_loss: 44542.9360\n","Epoch 20/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44469.8709 - regularization_loss: 0.0000e+00 - total_loss: 44469.8709\n","Epoch 21/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44403.6811 - regularization_loss: 0.0000e+00 - total_loss: 44403.6811\n","Epoch 22/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44343.2258 - regularization_loss: 0.0000e+00 - total_loss: 44343.2258\n","Epoch 23/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44287.8914 - regularization_loss: 0.0000e+00 - total_loss: 44287.8914\n","Epoch 24/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44236.9432 - regularization_loss: 0.0000e+00 - total_loss: 44236.9432\n","Epoch 25/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44189.9182 - regularization_loss: 0.0000e+00 - total_loss: 44189.9182\n","Epoch 26/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44146.2904 - regularization_loss: 0.0000e+00 - total_loss: 44146.2904\n","Epoch 27/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44105.7646 - regularization_loss: 0.0000e+00 - total_loss: 44105.7646\n","Epoch 28/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44067.9430 - regularization_loss: 0.0000e+00 - total_loss: 44067.9430\n","Epoch 29/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 44032.6058 - regularization_loss: 0.0000e+00 - total_loss: 44032.6058\n","Epoch 30/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43999.4496 - regularization_loss: 0.0000e+00 - total_loss: 43999.4496\n","Epoch 31/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43968.3085 - regularization_loss: 0.0000e+00 - total_loss: 43968.3085\n","Epoch 32/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43938.9500 - regularization_loss: 0.0000e+00 - total_loss: 43938.9500\n","Epoch 33/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43911.2599 - regularization_loss: 0.0000e+00 - total_loss: 43911.2599\n","Epoch 34/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43885.0389 - regularization_loss: 0.0000e+00 - total_loss: 43885.0389\n","Epoch 35/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43860.2223 - regularization_loss: 0.0000e+00 - total_loss: 43860.2223\n","Epoch 36/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43836.6318 - regularization_loss: 0.0000e+00 - total_loss: 43836.6318\n","Epoch 37/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43814.2335 - regularization_loss: 0.0000e+00 - total_loss: 43814.2335\n","Epoch 38/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43792.8729 - regularization_loss: 0.0000e+00 - total_loss: 43792.8729\n","Epoch 39/200\n","82/82 [==============================] - 3s 37ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43772.5338 - regularization_loss: 0.0000e+00 - total_loss: 43772.5338\n","Epoch 40/200\n","82/82 [==============================] - 3s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43753.0784 - regularization_loss: 0.0000e+00 - total_loss: 43753.0784\n","Epoch 41/200\n","82/82 [==============================] - 3s 37ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43734.5054 - regularization_loss: 0.0000e+00 - total_loss: 43734.5054\n","Epoch 42/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43716.6884 - regularization_loss: 0.0000e+00 - total_loss: 43716.6884\n","Epoch 43/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43699.6386 - regularization_loss: 0.0000e+00 - total_loss: 43699.6386\n","Epoch 44/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43683.2461 - regularization_loss: 0.0000e+00 - total_loss: 43683.2461\n","Epoch 45/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43667.5263 - regularization_loss: 0.0000e+00 - total_loss: 43667.5263\n","Epoch 46/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43652.3815 - regularization_loss: 0.0000e+00 - total_loss: 43652.3815\n","Epoch 47/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43637.8298 - regularization_loss: 0.0000e+00 - total_loss: 43637.8298\n","Epoch 48/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43623.7830 - regularization_loss: 0.0000e+00 - total_loss: 43623.7830\n","Epoch 49/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43610.2646 - regularization_loss: 0.0000e+00 - total_loss: 43610.2646\n","Epoch 50/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43597.1908 - regularization_loss: 0.0000e+00 - total_loss: 43597.1908\n","Epoch 51/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43584.5920 - regularization_loss: 0.0000e+00 - total_loss: 43584.5920\n","Epoch 52/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43572.3821 - regularization_loss: 0.0000e+00 - total_loss: 43572.3821\n","Epoch 53/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43560.5980 - regularization_loss: 0.0000e+00 - total_loss: 43560.5980\n","Epoch 54/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43549.1638 - regularization_loss: 0.0000e+00 - total_loss: 43549.1638\n","Epoch 55/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43538.1133 - regularization_loss: 0.0000e+00 - total_loss: 43538.1133\n","Epoch 56/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43527.3810 - regularization_loss: 0.0000e+00 - total_loss: 43527.3810\n","Epoch 57/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43516.9901 - regularization_loss: 0.0000e+00 - total_loss: 43516.9901\n","Epoch 58/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43506.8881 - regularization_loss: 0.0000e+00 - total_loss: 43506.8881\n","Epoch 59/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43497.0988 - regularization_loss: 0.0000e+00 - total_loss: 43497.0988\n","Epoch 60/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43487.5664 - regularization_loss: 0.0000e+00 - total_loss: 43487.5664\n","Epoch 61/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43478.3215 - regularization_loss: 0.0000e+00 - total_loss: 43478.3215\n","Epoch 62/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43469.3059 - regularization_loss: 0.0000e+00 - total_loss: 43469.3059\n","Epoch 63/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43460.5559 - regularization_loss: 0.0000e+00 - total_loss: 43460.5559\n","Epoch 64/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43452.0134 - regularization_loss: 0.0000e+00 - total_loss: 43452.0134\n","Epoch 65/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43443.7149 - regularization_loss: 0.0000e+00 - total_loss: 43443.7149\n","Epoch 66/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43435.6070 - regularization_loss: 0.0000e+00 - total_loss: 43435.6070\n","Epoch 67/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43427.7215 - regularization_loss: 0.0000e+00 - total_loss: 43427.7215\n","Epoch 68/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43420.0123 - regularization_loss: 0.0000e+00 - total_loss: 43420.0123\n","Epoch 69/200\n","82/82 [==============================] - 3s 33ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43412.5089 - regularization_loss: 0.0000e+00 - total_loss: 43412.5089\n","Epoch 70/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43405.1668 - regularization_loss: 0.0000e+00 - total_loss: 43405.1668\n","Epoch 71/200\n","82/82 [==============================] - 2s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43398.0153 - regularization_loss: 0.0000e+00 - total_loss: 43398.0153\n","Epoch 72/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43391.0113 - regularization_loss: 0.0000e+00 - total_loss: 43391.0113\n","Epoch 73/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43384.1842 - regularization_loss: 0.0000e+00 - total_loss: 43384.1842\n","Epoch 74/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43377.4942 - regularization_loss: 0.0000e+00 - total_loss: 43377.4942\n","Epoch 75/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43370.9694 - regularization_loss: 0.0000e+00 - total_loss: 43370.9694\n","Epoch 76/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43364.5696 - regularization_loss: 0.0000e+00 - total_loss: 43364.5696\n","Epoch 77/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43358.3225 - regularization_loss: 0.0000e+00 - total_loss: 43358.3225\n","Epoch 78/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43352.1919 - regularization_loss: 0.0000e+00 - total_loss: 43352.1919\n","Epoch 79/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43346.2047 - regularization_loss: 0.0000e+00 - total_loss: 43346.2047\n","Epoch 80/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43340.3265 - regularization_loss: 0.0000e+00 - total_loss: 43340.3265\n","Epoch 81/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43334.5842 - regularization_loss: 0.0000e+00 - total_loss: 43334.5842\n","Epoch 82/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43328.9398 - regularization_loss: 0.0000e+00 - total_loss: 43328.9398\n","Epoch 83/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43323.4216 - regularization_loss: 0.0000e+00 - total_loss: 43323.4216\n","Epoch 84/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43317.9976 - regularization_loss: 0.0000e+00 - total_loss: 43317.9976\n","Epoch 85/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43312.6923 - regularization_loss: 0.0000e+00 - total_loss: 43312.6923\n","Epoch 86/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43307.4751 - regularization_loss: 0.0000e+00 - total_loss: 43307.4751\n","Epoch 87/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43302.3698 - regularization_loss: 0.0000e+00 - total_loss: 43302.3698\n","Epoch 88/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43297.3429 - regularization_loss: 0.0000e+00 - total_loss: 43297.3429\n","Epoch 89/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43292.4234 - regularization_loss: 0.0000e+00 - total_loss: 43292.4234\n","Epoch 90/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43287.5797 - regularization_loss: 0.0000e+00 - total_loss: 43287.5797\n","Epoch 91/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43282.8360 - regularization_loss: 0.0000e+00 - total_loss: 43282.8360\n","Epoch 92/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43278.1644 - regularization_loss: 0.0000e+00 - total_loss: 43278.1644\n","Epoch 93/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43273.5847 - regularization_loss: 0.0000e+00 - total_loss: 43273.5847\n","Epoch 94/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43269.0726 - regularization_loss: 0.0000e+00 - total_loss: 43269.0726\n","Epoch 95/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43264.6498 - regularization_loss: 0.0000e+00 - total_loss: 43264.6498\n","Epoch 96/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43260.2916 - regularization_loss: 0.0000e+00 - total_loss: 43260.2916\n","Epoch 97/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43256.0154 - regularization_loss: 0.0000e+00 - total_loss: 43256.0154\n","Epoch 98/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43251.8016 - regularization_loss: 0.0000e+00 - total_loss: 43251.8016\n","Epoch 99/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43247.6642 - regularization_loss: 0.0000e+00 - total_loss: 43247.6642\n","Epoch 100/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43243.5863 - regularization_loss: 0.0000e+00 - total_loss: 43243.5863\n","Epoch 101/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43239.5816 - regularization_loss: 0.0000e+00 - total_loss: 43239.5816\n","Epoch 102/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43235.6329 - regularization_loss: 0.0000e+00 - total_loss: 43235.6329\n","Epoch 103/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43231.7535 - regularization_loss: 0.0000e+00 - total_loss: 43231.7535\n","Epoch 104/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43227.9268 - regularization_loss: 0.0000e+00 - total_loss: 43227.9268\n","Epoch 105/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43224.1661 - regularization_loss: 0.0000e+00 - total_loss: 43224.1661\n","Epoch 106/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43220.4557 - regularization_loss: 0.0000e+00 - total_loss: 43220.4557\n","Epoch 107/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43216.8076 - regularization_loss: 0.0000e+00 - total_loss: 43216.8076\n","Epoch 108/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43213.2076 - regularization_loss: 0.0000e+00 - total_loss: 43213.2076\n","Epoch 109/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43209.6674 - regularization_loss: 0.0000e+00 - total_loss: 43209.6674\n","Epoch 110/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43206.1724 - regularization_loss: 0.0000e+00 - total_loss: 43206.1724\n","Epoch 111/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43202.7340 - regularization_loss: 0.0000e+00 - total_loss: 43202.7340\n","Epoch 112/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43199.3387 - regularization_loss: 0.0000e+00 - total_loss: 43199.3387\n","Epoch 113/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43195.9977 - regularization_loss: 0.0000e+00 - total_loss: 43195.9977\n","Epoch 114/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43192.6978 - regularization_loss: 0.0000e+00 - total_loss: 43192.6978\n","Epoch 115/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43189.4501 - regularization_loss: 0.0000e+00 - total_loss: 43189.4501\n","Epoch 116/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43186.2408 - regularization_loss: 0.0000e+00 - total_loss: 43186.2408\n","Epoch 117/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43183.0811 - regularization_loss: 0.0000e+00 - total_loss: 43183.0811\n","Epoch 118/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43179.9584 - regularization_loss: 0.0000e+00 - total_loss: 43179.9584\n","Epoch 119/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43176.8842 - regularization_loss: 0.0000e+00 - total_loss: 43176.8842\n","Epoch 120/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43173.8445 - regularization_loss: 0.0000e+00 - total_loss: 43173.8445\n","Epoch 121/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43170.8511 - regularization_loss: 0.0000e+00 - total_loss: 43170.8511\n","Epoch 122/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43167.8898 - regularization_loss: 0.0000e+00 - total_loss: 43167.8898\n","Epoch 123/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43164.9737 - regularization_loss: 0.0000e+00 - total_loss: 43164.9737\n","Epoch 124/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43162.0891 - regularization_loss: 0.0000e+00 - total_loss: 43162.0891\n","Epoch 125/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43159.2478 - regularization_loss: 0.0000e+00 - total_loss: 43159.2478\n","Epoch 126/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43156.4350 - regularization_loss: 0.0000e+00 - total_loss: 43156.4350\n","Epoch 127/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43153.6648 - regularization_loss: 0.0000e+00 - total_loss: 43153.6648\n","Epoch 128/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43150.9214 - regularization_loss: 0.0000e+00 - total_loss: 43150.9214\n","Epoch 129/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43148.2196 - regularization_loss: 0.0000e+00 - total_loss: 43148.2196\n","Epoch 130/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43145.5432 - regularization_loss: 0.0000e+00 - total_loss: 43145.5432\n","Epoch 131/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43142.9063 - regularization_loss: 0.0000e+00 - total_loss: 43142.9063\n","Epoch 132/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43140.2936 - regularization_loss: 0.0000e+00 - total_loss: 43140.2936\n","Epoch 133/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43137.7200 - regularization_loss: 0.0000e+00 - total_loss: 43137.7200\n","Epoch 134/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43135.1695 - regularization_loss: 0.0000e+00 - total_loss: 43135.1695\n","Epoch 135/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43132.6558 - regularization_loss: 0.0000e+00 - total_loss: 43132.6558\n","Epoch 136/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43130.1644 - regularization_loss: 0.0000e+00 - total_loss: 43130.1644\n","Epoch 137/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43127.7086 - regularization_loss: 0.0000e+00 - total_loss: 43127.7086\n","Epoch 138/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43125.2747 - regularization_loss: 0.0000e+00 - total_loss: 43125.2747\n","Epoch 139/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43122.8752 - regularization_loss: 0.0000e+00 - total_loss: 43122.8752\n","Epoch 140/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43120.4961 - regularization_loss: 0.0000e+00 - total_loss: 43120.4961\n","Epoch 141/200\n","82/82 [==============================] - 3s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43118.1502 - regularization_loss: 0.0000e+00 - total_loss: 43118.1502\n","Epoch 142/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43115.8241 - regularization_loss: 0.0000e+00 - total_loss: 43115.8241\n","Epoch 143/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43113.5296 - regularization_loss: 0.0000e+00 - total_loss: 43113.5296\n","Epoch 144/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43111.2551 - regularization_loss: 0.0000e+00 - total_loss: 43111.2551\n","Epoch 145/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43109.0104 - regularization_loss: 0.0000e+00 - total_loss: 43109.0104\n","Epoch 146/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43106.7851 - regularization_loss: 0.0000e+00 - total_loss: 43106.7851\n","Epoch 147/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43104.5882 - regularization_loss: 0.0000e+00 - total_loss: 43104.5882\n","Epoch 148/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43102.4099 - regularization_loss: 0.0000e+00 - total_loss: 43102.4099\n","Epoch 149/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43100.2598 - regularization_loss: 0.0000e+00 - total_loss: 43100.2598\n","Epoch 150/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43098.1273 - regularization_loss: 0.0000e+00 - total_loss: 43098.1273\n","Epoch 151/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43096.0218 - regularization_loss: 0.0000e+00 - total_loss: 43096.0218\n","Epoch 152/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43093.9332 - regularization_loss: 0.0000e+00 - total_loss: 43093.9332\n","Epoch 153/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43091.8711 - regularization_loss: 0.0000e+00 - total_loss: 43091.8711\n","Epoch 154/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43089.8252 - regularization_loss: 0.0000e+00 - total_loss: 43089.8252\n","Epoch 155/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43087.8048 - regularization_loss: 0.0000e+00 - total_loss: 43087.8048\n","Epoch 156/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43085.8000 - regularization_loss: 0.0000e+00 - total_loss: 43085.8000\n","Epoch 157/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43083.8202 - regularization_loss: 0.0000e+00 - total_loss: 43083.8202\n","Epoch 158/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43081.8553 - regularization_loss: 0.0000e+00 - total_loss: 43081.8553\n","Epoch 159/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43079.9145 - regularization_loss: 0.0000e+00 - total_loss: 43079.9145\n","Epoch 160/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43077.9879 - regularization_loss: 0.0000e+00 - total_loss: 43077.9879\n","Epoch 161/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43076.0847 - regularization_loss: 0.0000e+00 - total_loss: 43076.0847\n","Epoch 162/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43074.1955 - regularization_loss: 0.0000e+00 - total_loss: 43074.1955\n","Epoch 163/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43072.3298 - regularization_loss: 0.0000e+00 - total_loss: 43072.3298\n","Epoch 164/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43070.4760 - regularization_loss: 0.0000e+00 - total_loss: 43070.4760\n","Epoch 165/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43068.6455 - regularization_loss: 0.0000e+00 - total_loss: 43068.6455\n","Epoch 166/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43066.8266 - regularization_loss: 0.0000e+00 - total_loss: 43066.8266\n","Epoch 167/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43065.0305 - regularization_loss: 0.0000e+00 - total_loss: 43065.0305\n","Epoch 168/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43063.2456 - regularization_loss: 0.0000e+00 - total_loss: 43063.2456\n","Epoch 169/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43061.4829 - regularization_loss: 0.0000e+00 - total_loss: 43061.4829\n","Epoch 170/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43059.7307 - regularization_loss: 0.0000e+00 - total_loss: 43059.7307\n","Epoch 171/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43058.0005 - regularization_loss: 0.0000e+00 - total_loss: 43058.0005\n","Epoch 172/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43056.2800 - regularization_loss: 0.0000e+00 - total_loss: 43056.2800\n","Epoch 173/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43054.5804 - regularization_loss: 0.0000e+00 - total_loss: 43054.5804\n","Epoch 174/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43052.8910 - regularization_loss: 0.0000e+00 - total_loss: 43052.8910\n","Epoch 175/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43051.2222 - regularization_loss: 0.0000e+00 - total_loss: 43051.2222\n","Epoch 176/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43049.5627 - regularization_loss: 0.0000e+00 - total_loss: 43049.5627\n","Epoch 177/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43047.9233 - regularization_loss: 0.0000e+00 - total_loss: 43047.9233\n","Epoch 178/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43046.2926 - regularization_loss: 0.0000e+00 - total_loss: 43046.2926\n","Epoch 179/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43044.6817 - regularization_loss: 0.0000e+00 - total_loss: 43044.6817\n","Epoch 180/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43043.0793 - regularization_loss: 0.0000e+00 - total_loss: 43043.0793\n","Epoch 181/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43041.4965 - regularization_loss: 0.0000e+00 - total_loss: 43041.4965\n","Epoch 182/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43039.9215 - regularization_loss: 0.0000e+00 - total_loss: 43039.9215\n","Epoch 183/200\n","82/82 [==============================] - 3s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43038.3653 - regularization_loss: 0.0000e+00 - total_loss: 43038.3653\n","Epoch 184/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43036.8171 - regularization_loss: 0.0000e+00 - total_loss: 43036.8171\n","Epoch 185/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43035.2869 - regularization_loss: 0.0000e+00 - total_loss: 43035.2869\n","Epoch 186/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43033.7646 - regularization_loss: 0.0000e+00 - total_loss: 43033.7646\n","Epoch 187/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43032.2603 - regularization_loss: 0.0000e+00 - total_loss: 43032.2603\n","Epoch 188/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43030.7631 - regularization_loss: 0.0000e+00 - total_loss: 43030.7631\n","Epoch 189/200\n","82/82 [==============================] - 2s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43029.2829 - regularization_loss: 0.0000e+00 - total_loss: 43029.2829\n","Epoch 190/200\n","82/82 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43027.8102 - regularization_loss: 0.0000e+00 - total_loss: 43027.8102\n","Epoch 191/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43026.3549 - regularization_loss: 0.0000e+00 - total_loss: 43026.3549\n","Epoch 192/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43024.9057 - regularization_loss: 0.0000e+00 - total_loss: 43024.9057\n","Epoch 193/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43023.4735 - regularization_loss: 0.0000e+00 - total_loss: 43023.4735\n","Epoch 194/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43022.0478 - regularization_loss: 0.0000e+00 - total_loss: 43022.0478\n","Epoch 195/200\n","82/82 [==============================] - 3s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43020.6384 - regularization_loss: 0.0000e+00 - total_loss: 43020.6384\n","Epoch 196/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43019.2354 - regularization_loss: 0.0000e+00 - total_loss: 43019.2354\n","Epoch 197/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43017.8480 - regularization_loss: 0.0000e+00 - total_loss: 43017.8480\n","Epoch 198/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43016.4669 - regularization_loss: 0.0000e+00 - total_loss: 43016.4669\n","Epoch 199/200\n","82/82 [==============================] - 2s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43015.1009 - regularization_loss: 0.0000e+00 - total_loss: 43015.1009\n","Epoch 200/200\n","82/82 [==============================] - 2s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 43013.7418 - regularization_loss: 0.0000e+00 - total_loss: 43013.7418\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf_keras.src.callbacks.History at 0x7fa66bee6e30>"]},"metadata":{},"execution_count":32}],"source":["model.fit(cached_train, epochs=200)"]},{"cell_type":"markdown","source":["As the model trains, the loss is falling and a set of top-k retrieval metrics is updated. These tell us whether the true positive is in the top-k retrieved items from the entire candidate set. For example, a top-5 categorical accuracy metric of 0.2 would tell us that, on average, the true positive is in the top 5 retrieved items 20% of the time.\n","\n","Note that, in this example, we evaluate the metrics during training as well as evaluation. Because this can be quite slow with large candidate sets, it may be prudent to turn metric calculation off in training, and only run it in evaluation.\n","\n","Finally, we can evaluate our model on the test set:"],"metadata":{"id":"bFuNY5UOZzdp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sIpdODPzQI-q"},"outputs":[],"source":["# Since this model creates just a retrival index, it is suitable to use the test dataset also for training to index them as well.\n","# Because no unseen data/queries are given as input to this model under any circumstance, the model doesn't need to generalise to unseen data.\n","# Therefore, following code snippet to test the model is ommitted during execution.\n","\n","\n","#model.evaluate(cached_test, return_dict=True)"]},{"cell_type":"markdown","source":["## Making predictions\n","\n","Now that we have a model, we would like to be able to make predictions. We can use the `tfrs.layers.factorized_top_k.BruteForc`e layer to do this."],"metadata":{"id":"j2pQo_REcgxK"}},{"cell_type":"code","source":["unique_employee_ids = tf.constant(unique_employee_ids)  # Convert to Tensor to make the data (numpy array) ready for subsequent TensorFlow operations\n","unique_employee_ids = tf.data.Dataset.from_tensor_slices(unique_employee_ids)  # Convert the tensor into a Dataset"],"metadata":{"id":"_eTWxZ89kU1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a model that takes in raw query features, and\n","index = tfrs.layers.factorized_top_k.BruteForce(model.category_model, k=1000)\n","# recommends employees out of the entire unique employee dataset.\n","index.index_from_dataset(\n","  tf.data.Dataset.zip((unique_employee_ids.batch(1000), unique_employee_ids.batch(1000).map(model.employee_model)))\n",")\n","\n","# Get recommendations.\n","_, employee_ids = index(tf.constant([\"Electricians\"]), k=20)\n","print(f\"Recommendations for category 'Electricians': {employee_ids[0, :5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyuWYIy5c9uc","executionInfo":{"status":"ok","timestamp":1736088303004,"user_tz":-330,"elapsed":547,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"d37fa266-d416-4559-ac1c-72f677deff06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recommendations for category 'Electricians': [b'z7otfCcjH3Awwck7nsEEqQ' b'QL3xkxLAe788em3_3eC4LQ'\n"," b'TCtVAiGDb05PyLe3v-zXDA' b'1xeRysU0YYOnpy-5_3ySag'\n"," b'HTHUzTl-vDhEcbh7bZfhIg']\n"]}]},{"cell_type":"code","source":["print(len(employee_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihC9iajulcLF","executionInfo":{"status":"ok","timestamp":1736088303004,"user_tz":-330,"elapsed":10,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"e2b0a9d7-49ac-4c90-f2e9-e940013105e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20\n"]}]},{"cell_type":"markdown","source":["Of course, the BruteForce layer is going to be too slow to serve a model with many possible candidates. The following sections shows how to speed this up by using an approximate retrieval index."],"metadata":{"id":"fcwpvTWTj079"}},{"cell_type":"code","source":[],"metadata":{"id":"V7RBsTunj140"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["An approximate retrieval index to speed up predictions. This will make it possible to efficiently surface recommendations from sets of tens of millions of candidates.\n","\n","To do so, we can use the `scann` package. This is an optional dependency of TFRS, and we installed it separately at the beginning of this notebook by calling `!pip install -q scann`.\n","\n","Once installed we can use the TFRS `ScaNN` layer:"],"metadata":{"id":"v6LiHiP5j8h9"}},{"cell_type":"code","source":["# Create a model that takes in raw query features, and\n","scann_index = tfrs.layers.factorized_top_k.ScaNN(model.category_model, k=1000)\n","# recommends employees out of the entire unique employee dataset.\n","scann_index.index_from_dataset(\n","  tf.data.Dataset.zip((unique_employee_ids.batch(1000), unique_employee_ids.batch(1000).map(model.employee_model)))\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rhJe2YzBkMiN","executionInfo":{"status":"ok","timestamp":1736088308182,"user_tz":-330,"elapsed":5184,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"f448f326-0bc1-4584-f24b-a7d076afe119"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7fa66bf46110>"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["This layer will perform approximate lookups: this makes retrieval slightly less accurate, but orders of magnitude faster on large candidate sets."],"metadata":{"id":"MWAGxbrnkOwj"}},{"cell_type":"code","source":["# Get recommendations.\n","_, employee_ids = scann_index(tf.constant([\"Electricians\"]), k=20)\n","print(f\"Recommendations for category 'Electricians': {employee_ids[0, :5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FhU1h6pdkPM5","executionInfo":{"status":"ok","timestamp":1736088308182,"user_tz":-330,"elapsed":14,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"2f31646a-a0af-423f-c603-e0d91dd510af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recommendations for category 'Electricians': [b'TCtVAiGDb05PyLe3v-zXDA' b'HTHUzTl-vDhEcbh7bZfhIg'\n"," b'QBVZcOmWi-dK4HOcmnNrLg' b'z7otfCcjH3Awwck7nsEEqQ'\n"," b'DD4gTG-FeG_nneXcexJ2eg']\n"]}]},{"cell_type":"code","source":["print(len(employee_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqHAFlYelgfN","executionInfo":{"status":"ok","timestamp":1736088308182,"user_tz":-330,"elapsed":13,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"5282f6b2-ed72-4bcb-94d2-8a4da721cea7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20\n"]}]},{"cell_type":"markdown","source":["# Model serving\n","\n","After the model is trained, we need a way to deploy it.\n","\n","In a two-tower retrieval model, serving has two components:\n","\n","\n","*   **a serving query model**, taking in features of the query and transforming them into a query embedding, and\n","*   **a serving candidate model**. This most often takes the form of an approximate nearest neighbours (ANN) index which allows fast approximate lookup of candidates in response to a query produced by the query model.\n","\n","\n","In TFRS, both components can be packaged into a single exportable model, giving us a model that takes the raw category names and returns the ids of top/most similar employees for that category. This is done via exporting the model to a `SavedModel` format, which makes it possible to serve using TensorFlow Serving.\n","\n","To deploy a model like this, we simply export the `BruteForce` layer and/or `ScaNN` layer we created above:"],"metadata":{"id":"4yBsym4DrXIA"}},{"cell_type":"code","source":["# Export the query model.\n","with tempfile.TemporaryDirectory() as tmp:\n","  path = os.path.join(tmp, \"model\")\n","\n","  # Save the index.\n","  tf.saved_model.save(\n","      scann_index,\n","      path,\n","      options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n","  )\n","\n","  # Load it back; can also be done in TensorFlow Serving.\n","  loaded = tf.saved_model.load(path)\n","\n","  # Pass a category name in, get top predicted employee ids back.\n","  scores, employee_ids = loaded(tf.constant([\"Electricians\"]))\n","\n","  print(f\"Recommendations for category 'Electricians': {employee_ids[0][:5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OaqDWO9sXsX","executionInfo":{"status":"ok","timestamp":1736088309206,"user_tz":-330,"elapsed":1034,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"ababe163-1933-4f5d-98bb-0b616fd7b5fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"]},{"output_type":"stream","name":"stdout","text":["Recommendations for category 'Electricians': [b'TCtVAiGDb05PyLe3v-zXDA' b'HTHUzTl-vDhEcbh7bZfhIg'\n"," b'QBVZcOmWi-dK4HOcmnNrLg' b'z7otfCcjH3Awwck7nsEEqQ'\n"," b'DD4gTG-FeG_nneXcexJ2eg']\n"]}]},{"cell_type":"code","source":["print(len(employee_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3rI2kmutf9Q","executionInfo":{"status":"ok","timestamp":1736088309206,"user_tz":-330,"elapsed":8,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"1af5e59e-33f4-460c-bc69-09d63bc40a17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n"]}]},{"cell_type":"code","source":["# Define the folder path for saving the model\n","save_dir = '/content/drive/My Drive/Colab Notebooks/Saved Models'\n","#save_dir = '/content/Saved Model'\n","\n","# Ensure the folder exists\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# Path to save the model\n","model_path = os.path.join(save_dir, \"recsys_model_one_retrieval\")\n","\n","# Save the ScaNN index\n","tf.saved_model.save(\n","    scann_index,\n","    model_path,\n","    options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",")\n","\n","# Load the model back\n","loaded = tf.saved_model.load(model_path)\n","\n","# Pass a category name and get top recommendations\n","scores, employee_ids = loaded(tf.constant([\"Electricians\"]))\n","\n","print(f\"Recommendations for category 'Electricians': {employee_ids[0][:5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kf93X5vJyT3I","executionInfo":{"status":"ok","timestamp":1736088311263,"user_tz":-330,"elapsed":2064,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"989e51b5-ce77-43f1-b33e-c0febb4c5285"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"]},{"output_type":"stream","name":"stdout","text":["Recommendations for category 'Electricians': [b'TCtVAiGDb05PyLe3v-zXDA' b'HTHUzTl-vDhEcbh7bZfhIg'\n"," b'QBVZcOmWi-dK4HOcmnNrLg' b'z7otfCcjH3Awwck7nsEEqQ'\n"," b'DD4gTG-FeG_nneXcexJ2eg']\n"]}]},{"cell_type":"code","source":["print(len(employee_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vb9HpNLX0Fqy","executionInfo":{"status":"ok","timestamp":1736088311263,"user_tz":-330,"elapsed":7,"user":{"displayName":"Oshan RODRIGO","userId":"10717969477656221923"}},"outputId":"6e682445-018c-4372-c1bb-8557fa2e8ab2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPWbnJ5sR7RQRoHIqZarXXj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}